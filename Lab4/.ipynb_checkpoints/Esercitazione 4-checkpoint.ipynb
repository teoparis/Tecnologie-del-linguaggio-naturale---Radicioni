{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe34c2c-0a02-4991-a579-f6fadf5955ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0797ee-e03f-462c-9f8b-eee35889babe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31130c55-85df-445c-81cb-af7cb83802cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea un dizionario, in cui ad ogni parola (chiave) corrisponde una lista\n",
    "# di babel synset presi del file \"SemEval17_IT_senses2sysensts.txt\"\n",
    "# es. un estratto:\n",
    "\"\"\"{.....'cifra': ['bn:00019153n', 'bn:00025702n', 'bn:00055715n', 'bn:01412291n', \n",
    "'bn:00034392n', 'bn:00024979n', 'bn:00058287n', 'bn:00034394n', 'bn:00003601n', \n",
    "'bn:00019155n'], \n",
    "   'dollaro': ['bn:00010038n', 'bn:00007240n', 'bn:00028115n', \n",
    " 'bn:00028114n', 'bn:00044648n', 'bn:00071729n', 'bn:00050950n', \n",
    " 'bn:00013472n', 'bn:00016907n', 'bn:15584900n', 'bn:00042310n', \n",
    " 'bn:00034409n', 'bn:00079129n', 'bn:00047909n', 'bn:00057522n', \n",
    " 'bn:00007961n', 'bn:00078306n', 'bn:00082043n', 'bn:00075926n', \n",
    " 'bn:00008503n', 'bn:00009726n', 'bn:14987182n', 'bn:00013578n', \n",
    " 'bn:00015129n'].....}\"\"\"\n",
    "\n",
    "\n",
    "def get_senses_dictionary(word_list):\n",
    "    senses_for_words = dict()\n",
    "    file = open(\"SemEval17_IT_senses2synsets.txt\", \"r\", encoding=\"utf8\")\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines)):\n",
    "        line = lines[i]\n",
    "        line = line.replace(\"\\n\", \"\").replace(\"#\", \"\")\n",
    "        if line in word_list:\n",
    "            while True:\n",
    "                i += 1\n",
    "                babel_synset = lines[i].replace(\"\\n\", \"\")\n",
    "                if \"#\" in babel_synset:  # vuol dire che non sto considerando più un babel synset\n",
    "                    break\n",
    "                if line not in senses_for_words:\n",
    "                    senses_for_words[line] = [babel_synset]\n",
    "                else:\n",
    "                    senses_for_words[line].append(babel_synset)\n",
    "    return senses_for_words\n",
    "\n",
    "\n",
    "# crea un dizionario delle annotazioni, in cui ad ogni coppia di parole\n",
    "# prese dal file delle annotazioni \"annotations1.tsv\" associa il valore\n",
    "# di similarità annotato da un essere umano\n",
    "\"\"\"es: un estratto {('terremoto', 'scossa'): '3.4', ('patrimonio', 'azione'): \n",
    "                 '0.3', ('ebreo', 'Gerusalemme'): '2.0', \n",
    "                 ('nuvolosità', 'previsione'): '1.2', \n",
    "                 ('dizionario', 'enciclopedia'): '3.1'....}\"\"\"\n",
    "\n",
    "\n",
    "def get_human_similarities_dictionary():\n",
    "    human_similarities = dict()\n",
    "    annotations_file = open(\"annotations1.tsv\")\n",
    "    read_tsv = csv.reader(annotations_file, delimiter=\"\\t\")\n",
    "    for row in read_tsv:\n",
    "        if row[0]:  # verifico che non sia una riga vuota (può capitare)\n",
    "            human_similarities[(row[0], row[1])] = row[2]\n",
    "    annotations_file.close()\n",
    "    return human_similarities\n",
    "\n",
    "\n",
    "# crea un dizionario delle annotazioni, in cui ad ogni coppia di parola\n",
    "# prese dal file delle annotazioni \"annotations2.tsv\" associa una coppia\n",
    "# di BABEL synset annotati da un essere umano sulla base delle annotazioni\n",
    "# di similarità del file \"annotations1.tsv\"\n",
    "\"\"\"es: un estratto {('terremoto', 'scossa'): ('bn:00029448n', 'bn:00029441n'), \n",
    "            ('patrimonio', 'azione'): ('bn:00080746n', 'bn:00070912n'), \n",
    "            ('ebreo', 'Gerusalemme'): ('bn:00043492n', 'bn:00015555n'),...}\"\"\"\n",
    "\n",
    "\n",
    "def get_human_synsets_dictionary():\n",
    "    human_synsets = dict()\n",
    "    annotations_file = open(\"annotations2.tsv\")\n",
    "    read_tsv = csv.reader(annotations_file, delimiter=\"\\t\")\n",
    "    for row in read_tsv:\n",
    "        if row[0]:  # verifico che non sia una riga vuota (può capitare)\n",
    "            human_synsets[(row[0], row[1])] = (row[2], row[3])\n",
    "    annotations_file.close()\n",
    "    return human_synsets\n",
    "\n",
    "\n",
    "# restituisce tutte le parole presenti nella coppie valutate nel dizionario\n",
    "# delle annotazioni umane che viene dato in input\n",
    "def get_word_list(human_similarities_dictionary):\n",
    "    word_list = []\n",
    "    for pair in human_similarities_dictionary.keys():\n",
    "        word_list.append(pair[0])\n",
    "        word_list.append(pair[1])\n",
    "    return word_list\n",
    "\n",
    "\n",
    "# crea una dizionario che associa ad ogni coppia di parole del dizionario\n",
    "# delle annotazioni umane delle similarità, un valore di similarità dato dalla massimizzazione della similarità\n",
    "# del coseno tra l'insieme dei vettori nasari associati ad una parola\n",
    "# e l'insieme dei vettori nasari associati all'altra parola\n",
    "# CONSEGNA 1\n",
    "def get_NASARI_similarities_dictionary(human_similarities_dictionary, senses_dictionary):\n",
    "    similarity_dictionary = dict()\n",
    "    for word_pair in human_similarities_dictionary:\n",
    "\n",
    "        try:\n",
    "            word1_senses = senses_dictionary[word_pair[0]]\n",
    "            word2_senses = senses_dictionary[word_pair[1]]\n",
    "\n",
    "            word1_vectors = get_NASARI_vectors(word1_senses)\n",
    "            word2_vectors = get_NASARI_vectors(word2_senses)\n",
    "\n",
    "            similarity_value = max_cosine_similarity(word1_vectors, word2_vectors)[0]\n",
    "\n",
    "            similarity_dictionary[word_pair] = similarity_value\n",
    "\n",
    "        except KeyError:  # una delle due parole della coppia non c'è nel file \"SemEval17_IT_senses2synsets.txt\"\n",
    "            print(\"La coppia \", word_pair, \"non e' stata valutata\")\n",
    "\n",
    "    return similarity_dictionary\n",
    "\n",
    "\n",
    "# crea un dizionario che associa ad ogni coppia di parole del dizionario\n",
    "# delle annotazioni umane dei sensi, una coppia di babel synset che massimizza la similarità\n",
    "# del coseno tra l'insieme dei vettori associati alla prima parola\n",
    "# e l'insieme dei vettori associati alla seconda parola\n",
    "# CONSEGNA 2\n",
    "def get_word_pair_synset_pair_dictionary(human_synsets_dictionary, senses_dictionary):\n",
    "    synsets_dictionary = dict()\n",
    "    for word_pair in human_synsets_dictionary:\n",
    "        try:\n",
    "            word1_senses = senses_dictionary[word_pair[0]]\n",
    "            word2_senses = senses_dictionary[word_pair[1]]\n",
    "\n",
    "            word1_vectors = get_NASARI_vectors(word1_senses)\n",
    "            word2_vectors = get_NASARI_vectors(word2_senses)\n",
    "\n",
    "            # TO-DO\n",
    "            synset_pair = max_cosine_similarity(word1_vectors, word2_vectors)[1]\n",
    "\n",
    "            synsets_dictionary[word_pair] = synset_pair\n",
    "\n",
    "        except KeyError:  # una delle due parole della coppia non c'è nel file \"SemEval17_IT_senses2synsets.txt\"\n",
    "            print(\"La coppia \", word_pair, \"non e' stata valutata\")\n",
    "    return synsets_dictionary\n",
    "\n",
    "\n",
    "# cerca un vettore NASARI per ogni babel synset in input\n",
    "# associati ad una parola. Resituisce un dizionario\n",
    "# che avrà come chiavi i babel synset e come valori\n",
    "# i vettori NASARI associati\n",
    "def get_NASARI_vectors(word_senses):\n",
    "    word_vectors = dict()\n",
    "\n",
    "    NASARI_file = open(\"mini_NASARI.tsv\")\n",
    "    read_tsv = csv.reader(NASARI_file, delimiter=\"\\t\")\n",
    "\n",
    "    for row in read_tsv:\n",
    "        babel_synset = row[0].split(\"__\")[0]\n",
    "        if babel_synset in word_senses:\n",
    "            vector = [float(val) for val in row[1:]]\n",
    "            word_vectors[babel_synset] = vector\n",
    "\n",
    "    NASARI_file.close()\n",
    "    return word_vectors\n",
    "\n",
    "\n",
    "# massimizza la cosine_similarity tra due liste di vettori distribuzionali\n",
    "def max_cosine_similarity(word_vector1, word_vectors2):\n",
    "    max_cos_similarity = 0\n",
    "    for babel_synset1 in word_vector1.keys():\n",
    "        for babel_synset2 in word_vectors2.keys():\n",
    "            cos_similarity = c_similarity(word_vector1[babel_synset1], word_vectors2[babel_synset2])\n",
    "            if cos_similarity > max_cos_similarity:\n",
    "                max_cos_similarity = cos_similarity\n",
    "                synset_pair = (babel_synset1, babel_synset2)\n",
    "    return max_cos_similarity, synset_pair\n",
    "\n",
    "\n",
    "# calcola la similarità del coseno tra due vettori numerici\n",
    "# restituisce quindi il rapporto tra il prodotto scalare die due vettori e il\n",
    "# prodotto della loro norma\n",
    "def c_similarity(vect1, vect2):\n",
    "    numerator = numpy.dot(vect1, vect2)\n",
    "    denominator = numpy.linalg.norm(vect1) * numpy.linalg.norm(vect2)\n",
    "\n",
    "    return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf092fb1-31fd-4a65-8758-19695eacaec8",
   "metadata": {},
   "source": [
    "SEMEVAL_MAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a2c825-8321-4dab-a3fe-fd243b0d2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Altamura       :\tcoppie nell'intervallo 201-250\n"
     ]
    }
   ],
   "source": [
    "# Mappa un cognome su uno dei 10 insiemi di coppie da annotare\n",
    "# \n",
    "# assegnare la variabile `input_name` con il proprio cognome\n",
    "def get_range(surname):\n",
    "    nof_elements = 500\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % 10)\n",
    "    idx_intervallo = base_idx * 50+1\n",
    "    return idx_intervallo\n",
    " \n",
    "\n",
    "input_name = \"Altamura\"\n",
    "\n",
    "values = []\n",
    "sx = get_range(input_name)\n",
    "values.append(sx)\n",
    "dx = sx+50-1\n",
    "intervallo = \"\" + str(sx) + \"-\" + str(dx)\n",
    "print('{:15}:\\tcoppie nell\\'intervallo {}'.format(input_name, intervallo))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1772928-d8c9-46d1-af30-f431e9361d92",
   "metadata": {},
   "source": [
    "ANNOTAZIONE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19915f76-5409-4cb2-8bb2-100534169f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "terremoto   scossa\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "patrimonio   azione\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "ebreo   Gerusalemme\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "nuvolosità   previsione\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "dizionario   enciclopedia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "zecca   museo\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "sedia   sgabello\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "spagnolo   umidità\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "lattina   bottiglia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "mosca   formica\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "mito   satira\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "centro della città   autobus\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "coda   Boeing 747-200\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "opera d'arte   artista\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "NATO   alleanza\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "re   sovrano\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "ritmo   cadenza\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "Alexander Fleming   penicillina\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "flauto   musica\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "airone cenerino   lago\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "viscosità   spruzzo\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "hardware   case\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "anello   fidanzamento\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "latino   tedesco\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "classe operaia   fabbrica\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "Shakespeare   Dickens\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "banconota   prete\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "strumento   lavoro\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "cinghiale nano   suidi\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "suffragio   uscita\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "stella   luminosità\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "trota   chitarra\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "dollaro   milionario\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "cifra   numero\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "burrasca   coperta\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "Obama   Clinton\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "personaggio secondario   film\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "Juventus   Bayern Monaco\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "cambiamento climatico   precipitazione\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "IA   batteria\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "capolavoro   Gioconda\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "crimine   aggressione\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "incoronazione   acqua\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "vocalista   pentagramma\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "spareggio   pallacanestro\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "forze armate   difesa\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "lago   nuvola\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "monastero   doccia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "lingua madre   lingua\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "porto   incarto\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire similaritÃ (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Altamura       :\tcoppie nell'intervallo 201-250\n",
    "\n",
    "\"\"\"\n",
    "INTERVAL_START = 201\n",
    "INTERVAL_END = 250\n",
    "\n",
    "\"\"\"\n",
    "Processo di annotazione manuale dell'utente'\n",
    "\"\"\"\n",
    "\n",
    "with open('annotations1.tsv', 'wt') as out_file:\n",
    "    # processo di annotazione. vengono prese le coppie di parole\n",
    "    # che vanno da INTERVAL_START  a INTERVAL_END e viene chiesto\n",
    "    # all'utente il punteggio di similaritÃ  [1-4]\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "\n",
    "    with open(\"it.test.data.txt\", \"r\", encoding=\"utf8\") as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            if i >= INTERVAL_START - 1:\n",
    "                line = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "                print(\"==============================\")\n",
    "                word1, word2 = line[0], line[1]\n",
    "                print(word1, \" \", word2)\n",
    "                similarity_value = float(input(\"Inserire similaritÃ (1-4): \"))\n",
    "                similarity_value = format(similarity_value, '.1f')\n",
    "                tsv_writer.writerow([word1, word2, similarity_value])\n",
    "                print(\"==============================\")\n",
    "            if i == INTERVAL_END - 1:\n",
    "                break\n",
    "    fp.close()\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba5896-484c-4cb7-9709-c14f74228bf3",
   "metadata": {},
   "source": [
    "ANNOTAZIONE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05dc2f0-5311-4f5c-80c0-55aa5730d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Altamura       :\tcoppie nell'intervallo 201-250\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('annotations2.tsv', 'wt') as out_file:\n",
    "    \n",
    "    #processo di annotazione manuale\n",
    "    ##Term1 Term2 BS1 BS2 Terms_in_BS1 Terms_in_BS2\n",
    "    \n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['terremoto', 'scossa', 'bn:00029448n','bn:00029441n','sisma,attività sismica,tremito','microsisma,microsismo'])\n",
    "    tsv_writer.writerow(['patrimonio', 'azione', 'bn:00080746n','bn:00070912n','ricchezza,ricco,facoltoso','compartecipazione,quota'])\n",
    "    tsv_writer.writerow(['ebreo', 'Gerusalemme', 'bn:00043492n','bn:00015555n','israelita,giudeo','Gerico'])\n",
    "    tsv_writer.writerow(['nuvolosità', 'previsione', 'bn:00020002n','bn:00004638n','nube,nembo','anticipazione,predizione,vaticinio'])\n",
    "    tsv_writer.writerow(['dizionario', 'enciclopedia', 'bn:00026967n','bn:00024746n','vocabolario,lessico,calepino','opera di consultazione'])\n",
    "    tsv_writer.writerow(['zecca', 'museo', 'bn:00055225n','bn:00056426n','monete','manufatti,scienza'])\n",
    "    tsv_writer.writerow(['sedia', 'sgabello', 'bn:00017515n','bn:00074427n','seggiola,gamba della sedia','panchetto'])\n",
    "    tsv_writer.writerow(['spagnolo', 'umidità', 'bn:00073092n','bn:00045190n','Lingua spagnola','vapore acqueo'])\n",
    "    tsv_writer.writerow(['lattina', 'bottiglia', 'bn:00072586n','bn:00012339n','bibite','contenitore d alluminio','vetro,liquidi'])\n",
    "    tsv_writer.writerow(['mosca', 'formica', 'bn:13319918n','bn:00004458n','insetto','insetto'])\n",
    "    tsv_writer.writerow(['mito', 'satira', 'bn:00056669n','bn:00013998n','racconto mitologico','caricatura'])\n",
    "    tsv_writer.writerow(['coda', 'Boeing 747-200', 'bn:00030590n','bn:03226093n','aeromobile,impennaggio','aereo'])\n",
    "    tsv_writer.writerow([\"opera d'arte\", 'artista', 'bn:00081581n','bn:00006182n','creazione artistica','attività artistica'])\n",
    "    tsv_writer.writerow(['NATO', 'alleanza', 'bn:00056978n','bn:03544293n','organizzazione internazionale','associazione,patto'])\n",
    "    tsv_writer.writerow(['re', 'sovrano', 'bn:00024097n','bn:00024097n','regnante','regnante'])\n",
    "    tsv_writer.writerow(['ritmo', 'cadenza', 'bn:00009396n','bn:00014520n','tempo','teoria musicale,composizione'])\n",
    "    tsv_writer.writerow(['Alexander Fleming', 'penicillina', 'bn:00002616n','bn:00061363n','medico,farmacologo','antibiotici'])\n",
    "    tsv_writer.writerow(['flauto', 'musica', 'bn:00035477n','bn:00056443n','aerofoni labiali','melomane'])\n",
    "    tsv_writer.writerow(['airone cenerino', 'lago', 'bn:16449236n','bn:00049709n','uccello','massa di acqua'])\n",
    "    tsv_writer.writerow(['viscosità', 'spruzzo', 'bn:00080092n','bn:00073618n','vischiosità,grandezza fisica','acqua'])\n",
    "    tsv_writer.writerow(['hardware', 'case', 'bn:00021480n','bn:00262368n','materiale informatico','informatica,computer'])\n",
    "    tsv_writer.writerow(['anello', 'fidanzamento', 'bn:00008287n','bn:00010152n','gioiello','fidanzata,promessa sposa,promessa'])\n",
    "    tsv_writer.writerow(['latino', 'tedesco', 'bn:00050161n','bn:00040293n','Lingua latina','Lingua tedesca'])\n",
    "    tsv_writer.writerow(['classe operaia', 'fabbrica', 'bn:00049570n','bn:00032675n','classe lavoratrice,lavoro,lavoranti','stabilimento,manifattura,impianto'])\n",
    "    tsv_writer.writerow(['Shakespeare', 'Dickens', 'bn:00008556n','bn:00017842n','drammaturgo,poeta inglese','scrittore,giornalista,reporter'])\n",
    "    tsv_writer.writerow(['banconota', 'prete', 'bn:00008375n','bn:00057892n','biglietto di banca,biglietto,cambiale','religione'])\n",
    "    tsv_writer.writerow(['strumento', 'lavoro', 'bn:00077585n','bn:14959529n','utensile,arnese','attività produttiva,compenso'])\n",
    "    tsv_writer.writerow(['cinghiale nano', 'suidi', 'bn:03100066n','bn:00033468n','suide','maiali'])\n",
    "    tsv_writer.writerow(['suffragio', 'uscita', 'bn:00067845n','bn:00032243n','diritto di voto','andare fuori'])\n",
    "    tsv_writer.writerow(['stella', 'luminosità', 'bn:00073964n','bn:14292145n','astro,sole','stella,energia elettromagnetica,astronomia'])\n",
    "    tsv_writer.writerow(['trota', 'chitarra', 'bn:00078435n','bn:00042150n','pesce','strumento musicale,corde'])\n",
    "    tsv_writer.writerow(['dollaro', 'milionario', 'bn:00079129n','bn:00055058n','biglietto verde,dollaro USA','patrimonio'])\n",
    "    tsv_writer.writerow(['cifra', 'numero', 'bn:00025702n','bn:00058285n','simbolo,numeri,sistema numerico','grandezze,ente astratto'])\n",
    "    tsv_writer.writerow(['burrasca', 'coperta', 'bn:00074458n','bn:00011119n','bufera,temporale,fortunale','coltre,copriletto'])\n",
    "    tsv_writer.writerow(['Obama', 'Clinton', 'bn:03330021n','bn:00010400n','politico,presidente','presidente'])\n",
    "    tsv_writer.writerow(['personaggio secondario', 'film', 'bn:00206836n','bn:00034481n','personaggio,narrazione','produzione cinematografica'])\n",
    "    tsv_writer.writerow(['Juventus', 'Bayern Monaco', 'bn:00876765n','bn:00963795n','Torino,società calcistica','società polisportiva tedesca,Bundesliga'])\n",
    "    tsv_writer.writerow(['cambiamento climatico', 'precipitazione', 'bn:00019782n','bn:00028483n','cambiamento del clima,mutamento climatico','precipitazione atmosferica'])\n",
    "    tsv_writer.writerow(['IA', 'batteria', 'bn:00002150n','bn:00009064n','intelligenza artificiale','pila elettrica,accumulatore'])\n",
    "    tsv_writer.writerow(['capolavoro', 'Gioconda', 'bn:00053738n','bn:03571983n','opera ben riuscita','dipinto'])\n",
    "    tsv_writer.writerow(['crimine', 'aggressione', 'bn:00023807n','bn:00002015n','reato,delitto,misfatto,fattaccio','aggressività,atto di violenza'])\n",
    "    tsv_writer.writerow(['incoronazione', 'acqua', 'bn:00022800n','bn:00042379n','investitura,coronazione,incoronamento','H2O,composto chimico,atomi di idrogeno'])\n",
    "    tsv_writer.writerow(['spareggio', 'pallacanestro', 'bn:00062962n','bn:00008889n','play-off','basket,basketball,cestismo'])\n",
    "    tsv_writer.writerow(['forze armate', 'difesa', 'bn:00005732n','bn:00025878n','forze militari,militari','azione militare,difendere'])\n",
    "    tsv_writer.writerow(['lago', 'nuvola', 'bn:00049709n','bn:00020002n','massa di acqua','nube,nembo'])\n",
    "    tsv_writer.writerow(['monastero', 'doccia', 'bn:13460974n','bn:00071324n','monaci,monache,religioni','acqua,strumento,persona'])\n",
    "    tsv_writer.writerow(['lingua madre', 'lingua', 'bn:00034782n','bn:00049911n','madrelingua,lingua materna','linguaggio,parlare,parlata'])\n",
    "    tsv_writer.writerow(['porto', 'incarto', 'bn:00063640n','bn:00060120n','litorale marittimo,struttura,riva','imballo'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d458e8-e56f-46d9-829d-4b0dc8d1cdd1",
   "metadata": {},
   "source": [
    "CONSEGNA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0345523-9f45-4c37-bce8-b12d33070db4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5709f6e29b85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Spearman Correlation: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspearman\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhuman_similarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNASARI_similarities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-5709f6e29b85>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhuman_similarities_dictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_human_similarities_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msenses_dictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_senses_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_word_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhuman_similarities_dictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ca9c2517b090>\u001b[0m in \u001b[0;36mget_human_similarities_dictionary\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mread_tsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotations_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_tsv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# verifico che non sia una riga vuota (può capitare)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mhuman_similarities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mannotations_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    human_similarities_dictionary = get_human_similarities_dictionary()\n",
    "    \n",
    "    senses_dictionary = get_senses_dictionary(get_word_list(human_similarities_dictionary))\n",
    "    \n",
    "    NASARI_similarities_dictionary = get_NASARI_similarities_dictionary(human_similarities_dictionary, senses_dictionary)\n",
    "\n",
    "    human_similarities = []\n",
    "    NASARI_similarities = []\n",
    "    for word_pair in human_similarities_dictionary.keys():\n",
    "        if word_pair in NASARI_similarities_dictionary.keys():\n",
    "            human_similarities.append(float(human_similarities_dictionary[word_pair]))\n",
    "            NASARI_similarities.append(NASARI_similarities_dictionary[word_pair])\n",
    "    \n",
    "    print()\n",
    "    print(\"VALUTAZIONI DI SIMILARITA' UMANE: \")\n",
    "    print(human_similarities_dictionary)\n",
    "    print()\n",
    "    print(\"VALUTAZIONI DI SIMILARITA' DEL SISTEMA: \")\n",
    "    print(NASARI_similarities_dictionary)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print(\"Pearson Correlation: \",np.corrcoef(human_similarities, NASARI_similarities))\n",
    "    print()\n",
    "    print(\"Spearman Correlation: \",sp.stats.spearman(human_similarities, NASARI_similarities))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6acaba0-3ca5-4b9a-b405-f8f10391425f",
   "metadata": {},
   "source": [
    "CONSEGNA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb78449-3aae-434a-ae25-8dcc3673a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    human_similarities_dictionary = get_human_similarities_dictionary()\n",
    "    \n",
    "    senses_dictionary = get_senses_dictionary(get_word_list(human_similarities_dictionary))\n",
    "    \n",
    "    human_synsets_dictionary = get_human_synsets_dictionary()\n",
    "    \n",
    "    word_pair_synset_pair_dictionary = get_word_pair_synset_pair_dictionary(human_synsets_dictionary, senses_dictionary)\n",
    "    \n",
    "    print()\n",
    "    print(\"ASSEGNAMENTI SYNSETS UMANI: \")\n",
    "    print(human_synsets_dictionary)\n",
    "    print()\n",
    "    print(\"'ASSEGNAMENTI SYNSETS DEL SISTEMA: \")\n",
    "    print(word_pair_synset_pair_dictionary)\n",
    "    \n",
    "    print()\n",
    "    #calcolo accuratezza sui singoli elementi\n",
    "    checked = 0\n",
    "    for word_pair in human_synsets_dictionary.keys():\n",
    "        synset_pair = word_pair_synset_pair_dictionary[word_pair]\n",
    "        human_synsets_pair = human_synsets_dictionary[word_pair]\n",
    "        if synset_pair[0] == human_synsets_pair[0]:\n",
    "            checked += 1\n",
    "        if synset_pair[1] == human_synsets_pair[1]:\n",
    "            checked += 1\n",
    "    evaluated = len(human_synsets_dictionary.keys()) * 2\n",
    "    print(\"Accuratezza sui singoli elmenti: \", checked / evaluated)\n",
    "            \n",
    "    #calcolo accuratezza sulle coppie\n",
    "    checked = 0\n",
    "    for word_pair in human_synsets_dictionary.keys():\n",
    "        synset_pair = word_pair_synset_pair_dictionary[word_pair]\n",
    "        human_synsets_pair = human_synsets_dictionary[word_pair]\n",
    "        if (synset_pair[0] == human_synsets_pair[0]) and (synset_pair[1] == human_synsets_pair[1]):\n",
    "            checked += 1\n",
    "    evaluated = len(human_synsets_dictionary.keys())\n",
    "    print(\"Accuratezza sulle coppie: \", checked / evaluated)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0cb04b-65de-4e05-849a-57d4c0947f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
