{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d193f124-fa2a-4a00-b3d6-f80910727f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import hashlib\n",
    "from random import randint\n",
    "from random import seed\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3929cf7-9127-49ed-a462-36582fbed7ac",
   "metadata": {},
   "source": [
    "FUNZIONI DI PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37821d28-7d95-4d3b-b14d-35b6186fbfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#il pre-processing consiste nella tokenizzazione, lemmatizzazione,\n",
    "#rimozione della punteggiatura e delle stopwords di una sentence\n",
    "def pre_processing(sentence):\n",
    "    return set(remove_stopwords(tokenize_sentence(remove_punctuation(sentence))))\n",
    "\n",
    "#Effettua la lemmatizzazione e rimuove le stowords da una lista di parole\n",
    "def remove_stopwords(words_list):\n",
    "    stopwords_list = get_stopwords()\n",
    "    return [value for value in words_list if value not in stopwords_list]\n",
    "\n",
    "#Rimuove la punteggiatura da una sentence\n",
    "#Restituisce la sentence senza punteggiature\n",
    "def remove_punctuation(sentence):\n",
    "    return re.sub(r'[^\\w\\s]','',sentence)\n",
    "\n",
    "#Tokenizza la frase in input e ne affettua anche la lemmatizzazione della sue parole\n",
    "def tokenize_sentence(sentence):\n",
    "    words_list = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        if (tag[1][:2] == \"NN\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos = wn.NOUN))\n",
    "        elif (tag[1][:2] == \"VB\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.VERB))\n",
    "        elif (tag[1][:2] == \"RB\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.ADV))\n",
    "        elif (tag[1][:2] == \"JJ\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.ADJ))\n",
    "    return words_list\n",
    "\n",
    "#Restituisce la l'insieme di stopwords dal file delle stopwords\n",
    "def get_stopwords():\n",
    "    stopwords = open(\"stop_words_FULL.txt\", \"r\")\n",
    "    stopwords_list = []\n",
    "    for word in stopwords:\n",
    "        stopwords_list.append(word.replace('\\n', ''))\n",
    "    stopwords.close()\n",
    "    return stopwords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c2efc-fd57-48a1-86fb-324d3012562d",
   "metadata": {},
   "source": [
    "FUNZIONI UTILI PER IL RITROVAMENTO DEI FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bbb14c6-b9c4-4d75-818f-f1623a010ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Struttura dati che contiene i contesti associati al frame, ai suoi frame elements e alle sue lexical units\n",
    "class ContextsFrame:\n",
    "    \n",
    "    def __init__(self, frame_id, frame_name, frame_context,frame_elements_contexts, lexical_units_contexts):\n",
    "        self.frame_id = frame_id\n",
    "        self.frame_name = frame_name\n",
    "        self.frame_context = frame_context\n",
    "        #dizionario: [frame_element_name] -> context\n",
    "        self.frame_elements_contexts = frame_elements_contexts\n",
    "        #dizionario: [lexical_unit_name] -> context\n",
    "        self.lexical_units_contexts = lexical_units_contexts\n",
    "        \n",
    "    def get_frame_elements_contexts(self):\n",
    "        return self.frame_elements_contexts\n",
    "    def get_lexical_units_contexts(self):\n",
    "        return self.lexical_units_contexts\n",
    "    def get_frame_id(self):\n",
    "        return self.frame_id\n",
    "    def get_frame_name(self):\n",
    "        return self.frame_name\n",
    "    def get_frame_context(self):\n",
    "        return self.frame_context\n",
    "    #stampa fatta al solo scopo di conoscere le struttura interna della classe\n",
    "    def printContextsFrame(self):\n",
    "        print(\"FRAME ID: \",self.get_frame_id())\n",
    "        print(\"FRAME NAME: \",self.get_frame_name())\n",
    "        print(\"\\nFRAME CONTEXT: \",self.get_frame_context())\n",
    "        print(\"\\nFRAME ELEMENTS CONTEXTS: \",self.get_frame_elements_contexts())\n",
    "        print(\"\\nLEXICAL UNITS CONTEXTS: \",self.get_lexical_units_contexts())\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "#Risultati di WordNet.\n",
    "#Struttura che contiene i synset associati al frame in questione, ai suoi frame elements e alle sue lexical_units\n",
    "#Questi risultati dovranno poi essere confrontati con annotazioni fatte degli umani\n",
    "#quindi ogni annotazione per ogni frame dovrà essere di questo tipo e.s SynsetsFrameAnnotation\n",
    "class SynsetsFrame:\n",
    "    def __init__(self, frame_id, frame_name, frame_synset,frame_elements_synsets, lexical_units_synsets):\n",
    "        self.frame_id = frame_id\n",
    "        self.frame_name = frame_name\n",
    "        self.frame_synset = frame_synset\n",
    "        self.frame_elements_synsets = frame_elements_synsets\n",
    "        self.lexical_units_synsets = lexical_units_synsets\n",
    "    def get_frame_elements_synsets(self):\n",
    "        return self.frame_elements_synsets\n",
    "    def get_lexical_units_synsets(self):\n",
    "        return self.lexical_units_synsets\n",
    "    def get_frame_id(self):\n",
    "        return self.frame_id\n",
    "    def get_frame_name(self):\n",
    "        return self.frame_name\n",
    "    def get_frame_synset(self):\n",
    "        return self.frame_synset\n",
    "    #stampa fatta al solo scopo di conoscere le struttura interna della classe\n",
    "    def printSynsetsFrame(self):\n",
    "        print(\"FRAME ID: \",self.get_frame_id())\n",
    "        print(\"FRAME NAME: \",self.get_frame_name())\n",
    "        print(\"FRAME SYNSET: \",self.get_frame_synset())\n",
    "        print(\"FRAME ELEMENTS SYNSETS: \",self.get_frame_elements_synsets())\n",
    "        print(\"LEXICAL UNITS SYNSETS: \",self.get_lexical_units_synsets())\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "def print_frames_with_IDs():\n",
    "    for x in fn.frames():\n",
    "        print('{}\\t{}'.format(x.ID, x.name))\n",
    "\n",
    "def get_frams_IDs():\n",
    "    return [f.ID for f in fn.frames()]   \n",
    "\n",
    "#restituisce un insieme di 5 frame legati allo cognome dello studente\n",
    "def getFrameSetForStudent(surname, list_len=5):\n",
    "    nof_frames = len(fn.frames())\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % nof_frames)\n",
    "    print('COGNOME STUDENTE: ' + surname + \"\\n\")\n",
    "    framenet_IDs = get_frams_IDs()\n",
    "    i = 0\n",
    "    offset = 0 \n",
    "    seed(1)\n",
    "    frame_list = []\n",
    "    while i < list_len:\n",
    "        fID = framenet_IDs[(base_idx+offset)%nof_frames]\n",
    "        f = fn.frame(fID)\n",
    "        frame_list.append(fn.frame(fID))\n",
    "        fNAME = f.name\n",
    "        #print('\\tID: {a:4d}\\tframe: {framename}'.format(a=fID, framename=fNAME))\n",
    "        offset = randint(0, nof_frames)\n",
    "        i += 1\n",
    "    return frame_list\n",
    "\n",
    "#Prende in input un frame di FrameNet e restituisce il suo contesto formato \n",
    "#da tutte le definizioni dei suoi frame element, lexical unit e del frame stesso\n",
    "def context_for_frame(frame):\n",
    "    context_frame = set()\n",
    "    context_frame.update(pre_processing(frame.definition))\n",
    "    \n",
    "    FEs = frame.FE.keys()\n",
    "    for fe in FEs:\n",
    "        fed = frame.FE[fe]\n",
    "        context_frame.update(pre_processing(fed.definition))\n",
    "    \n",
    "    LUs = frame.lexUnit.keys()\n",
    "    for lu in LUs:\n",
    "        lud = frame.lexUnit[lu]\n",
    "        context_frame.update(pre_processing(lud.definition))\n",
    "    \n",
    "    return context_frame\n",
    "\n",
    "#Restituisce il contesto per un frame component (frame element o lexical unit)\n",
    "#che è praticamente formato dalla sua definizione, lemmatizzata,\n",
    "#da cui sono state rimosse le stop words e punteggiatura\n",
    "def context_for_frame_component(frame_component):\n",
    "    context_frame_component = set()\n",
    "    context_frame_component.update(pre_processing(frame_component.definition))\n",
    "    \n",
    "    return context_frame_component\n",
    "\n",
    "#Prende in input un senso di WordNet e restituisce il suo contesto\n",
    "#formato da tutte le definizioni ed esempi dei suoi iperonimi, iponimi\n",
    "#e definizione ed esempi del senso stesso\n",
    "def context_for_sense(sense):\n",
    "    context_sense = set()\n",
    "\n",
    "    context_sense.update(pre_processing(sense.definition()))\n",
    "    for example in sense.examples():\n",
    "        context_sense.update(pre_processing(example))\n",
    "    \n",
    "    for hypernym in sense.hypernyms():\n",
    "        context_sense.update(pre_processing(hypernym.definition()))\n",
    "        for example in hypernym.examples():\n",
    "            context_sense.update(pre_processing(example))\n",
    "            \n",
    "    for hyponym in sense.hyponyms():\n",
    "        context_sense.update(pre_processing(hyponym.definition()))\n",
    "        for example in hyponym.examples():\n",
    "            context_sense.update(pre_processing(example))\n",
    "    return context_sense\n",
    "\n",
    "#Riceve in input una frase semplice(costituita da circa due parole separate da _)\n",
    "#e restituisce in output il reggente della frase\n",
    "def get_regent(sentence):\n",
    "    if sentence == 'Sleep':\n",
    "        return 'Sleep'\n",
    "    elif sentence == 'Be_on_alert':\n",
    "        return 'alert'\n",
    "    elif sentence == 'Rising_to_a_challenge':\n",
    "        return 'challenge'\n",
    "    elif sentence == 'Use_vehicle':\n",
    "        return 'vehicle'\n",
    "    elif sentence == 'Deciding':\n",
    "        return 'Deciding'\n",
    "\n",
    "#Le unità lessicali ricavate da FrameNet per un determinato frame sono nella forma <ul>.PoS (esempio: before.prep)\n",
    "#pertanto, per poter individuare il senso o i sensi corrispondenti all'unità lessicale, è importante rimuovere\n",
    "#il punto e il PoS che segue\n",
    "def remove_pos_lu(lexical_unit_name):\n",
    "    new_lexical_unit_name = lexical_unit_name.split(\".\")[0]\n",
    "    #Remove [...] from lexical_unit_name\n",
    "    return new_lexical_unit_name.split(\" [\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b3134-5816-4e57-beea-e1e77f3c40c3",
   "metadata": {},
   "source": [
    "ANNOTAZIONE DEI 5 FRAME ESTRATTI IN BASE AL COGNOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb4d0d2-6dc5-4831-86bb-be272eac1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "SURNAME = 'Parisi'\n",
    "\n",
    "\"\"\"\n",
    "student: Parisi\n",
    "\tID:  264\tframe: Sleep\n",
    "\tID: 2723\tframe: Be_on_alert\n",
    "\tID: 1441\tframe: Rising_to_a_challenge\n",
    "\tID: 1690\tframe: Use_vehicle\n",
    "\tID:  363\tframe: Deciding\n",
    "\"\"\"\n",
    "\n",
    "def get_synsets_frames_list_annotations():\n",
    "    \n",
    "    synsets_frames_list_annotations = []\n",
    "    \n",
    "    #FRAME 1\n",
    "    frame_id_1 = 264\n",
    "    frame_name_1 = 'Sleep'\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_1 = wn.synset('sleep.v.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_1 = dict()\n",
    "    frame_elements_synsets_1['Sleeper'] = wn.synset('sleeper.n.01')\n",
    "    frame_elements_synsets_1['Degree'] = wn.synset('degree.n.05')\n",
    "    frame_elements_synsets_1['Duration'] = wn.synset('duration.n.03')\n",
    "    frame_elements_synsets_1['Manner'] = wn.synset('manner.n.01')\n",
    "\n",
    "    #LUs\n",
    "    lexical_units_synsets_1 = dict()\n",
    "    lexical_units_synsets_1['asleep.n'] = wn.synset('sleep.n.01')\n",
    "    lexical_units_synsets_1['slumber.v'] = wn.synset('sleep.v.01')\n",
    "    lexical_units_synsets_1['snooze.n'] = wn.synset('nap.n.04')\n",
    "    lexical_units_synsets_1['snooze.v'] = wn.synset('catnap.v.01')\n",
    "    lexical_units_synsets_1['catnap.n'] = wn.synset('catnap.n.01')\n",
    "    lexical_units_synsets_1['doze.n'] = wn.synset('doze.n.01')\n",
    "\n",
    "    synsets_frame_1 = SynsetsFrame(frame_id_1, frame_name_1, frame_synset_1, frame_elements_synsets_1, lexical_units_synsets_1)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_1)\n",
    "    \n",
    "    #FRAME 2\n",
    "    frame_id_2 = 2723\n",
    "    frame_name_2 = \"Be_on_alert\"\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_2 = wn.synset('alert.n.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_2 = dict()\n",
    "    frame_elements_synsets_2['Activity'] = wn.synset('activity.n.01')\n",
    "    frame_elements_synsets_2['Danger'] = wn.synset('danger.n.01')\n",
    "    frame_elements_synsets_2['Protagonist'] = wn.synset('protagonist.n.01')\n",
    "    frame_elements_synsets_2['Time'] = wn.synset('time.n.06')\n",
    "    frame_elements_synsets_2['Degree'] = wn.synset('degree.n.05')\n",
    "    frame_elements_synsets_2['Duration'] = wn.synset('duration.n.03')\n",
    "    \n",
    "    #LUs\n",
    "    lexical_units_synsets_2 = dict()\n",
    "    lexical_units_synsets_2['alert.n'] = wn.synset('sleep.n.01')\n",
    "    lexical_units_synsets_2['guard.n'] = wn.synset('sleep.n.01')\n",
    "    \n",
    "    synsets_frame_2 = SynsetsFrame(frame_id_2, frame_name_2, frame_synset_2, frame_elements_synsets_2, lexical_units_synsets_2)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_2)\n",
    "    \n",
    "    #FRAME 3\n",
    "    frame_id_3 = 1441\n",
    "    frame_name_3 = \"Rising_to_a_challenge\"\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_3 = wn.synset('challenge.n.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_3 = dict()\n",
    "    frame_elements_synsets_3['Activity'] = wn.synset('activity.n.01')\n",
    "    frame_elements_synsets_3['Protagonist'] = wn.synset('protagonist.n.01')\n",
    "    frame_elements_synsets_3['Degree'] = wn.synset('degree.n.02')\n",
    "    frame_elements_synsets_3['Explanation'] = wn.synset('explanation.n.01')\n",
    "    frame_elements_synsets_3['Place'] = wn.synset('place.n.06')\n",
    "    frame_elements_synsets_3['Circumstances'] = wn.synset('circumstances.n.01')\n",
    "    \n",
    "    #LUs\n",
    "    lexical_units_synsets_3 = dict()\n",
    "    lexical_units_synsets_3['rise to the occasion.v'] = wn.synset('rise.v.06')\n",
    "    lexical_units_synsets_3['rise.v'] = wn.synset('rise.v.06')\n",
    "\n",
    "    \n",
    "    synsets_frame_3 = SynsetsFrame(frame_id_3, frame_name_3, frame_synset_3, frame_elements_synsets_3, lexical_units_synsets_3)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_3)\n",
    "    \n",
    "    #FRAME 4\n",
    "    frame_id_4 = 1690\n",
    "    frame_name_4 = 'Use_vehicle'\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_4 = wn.synset('vehicle.n.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_4 = dict()\n",
    "    frame_elements_synsets_4['Area'] = wn.synset('area.n.01')\n",
    "    frame_elements_synsets_4['Driver'] = wn.synset('driver.n.01')\n",
    "    frame_elements_synsets_4['Goal'] = wn.synset('goal.n.01')\n",
    "    frame_elements_synsets_4['Path'] = wn.synset('path.n.01')\n",
    "    frame_elements_synsets_4['Source'] = wn.synset('source.n.01')\n",
    "    frame_elements_synsets_4['Theme'] = wn.synset('theme.n.01')\n",
    "    frame_elements_synsets_4['Vehicle'] = wn.synset('vehicle.n.01')\n",
    "    frame_elements_synsets_4['Road'] = wn.synset('road.n.01')\n",
    "\n",
    "    #LUs\n",
    "    lexical_units_synsets_4 = dict()\n",
    "    \n",
    "    synsets_frame_4 = SynsetsFrame(frame_id_4, frame_name_4, frame_synset_4, frame_elements_synsets_4, lexical_units_synsets_4)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_4)\n",
    "    \n",
    "    #FRAME 5\n",
    "    frame_id_5 = 363\n",
    "    frame_name_5 = 'Deciding'\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_5 = wn.synset('decide.v.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_5 = dict()\n",
    "    frame_elements_synsets_5['Cognizer'] = wn.synset('decision.n.01')\n",
    "    frame_elements_synsets_5['Decision'] = wn.synset('decision.n.01')\n",
    "    frame_elements_synsets_5['Circumstance'] = wn.synset('circumstances.n.01')\n",
    "    frame_elements_synsets_5['Explanation'] = wn.synset('explanation.n.01')\n",
    "    frame_elements_synsets_5['Inherent_purpose'] = wn.synset('purpose.n.03')\n",
    "    frame_elements_synsets_5['Manner'] = wn.synset('manner.n.02')\n",
    "    frame_elements_synsets_5['Place'] = wn.synset('place.n.01')\n",
    "\n",
    "    #LUs\n",
    "    lexical_units_synsets_5 = dict()\n",
    "    lexical_units_synsets_5['decide.v'] = wn.synset('decide.v.01')\n",
    "    lexical_units_synsets_5['decision.n'] = wn.synset('decision.n.01')\n",
    "    lexical_units_synsets_5['determine.v'] = wn.synset('determine.v.01')\n",
    "\n",
    "    synsets_frame_5 = SynsetsFrame(frame_id_5, frame_name_5, frame_synset_5, frame_elements_synsets_5, lexical_units_synsets_5)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_5)\n",
    "    \n",
    "    return synsets_frames_list_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8fabc13-c6a8-4dad-9b8e-de0f31a00bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restituisce un oggetto SynsetsFrame della lista synsets_frames_list_annotations\n",
    "#con lo stesso frame_id dell'oggetto SynsetsFrame synsets_frame\n",
    "def get_synsets_frame_annotations(synsets_frame,synsets_frames_list_annotations):\n",
    "    for synsets_frame_annotations in synsets_frames_list_annotations:\n",
    "        if synsets_frame_annotations.get_frame_id() == synsets_frame.get_frame_id():\n",
    "            return synsets_frame_annotations\n",
    "\n",
    "def total_accuracy(synsets_frames_list, synsets_frames_list_annotations):\n",
    "    evaluated = 0\n",
    "    checked = 0\n",
    "    for synsets_frame in synsets_frames_list:\n",
    "        #prendo l'oggetto SynsetsFrame corrispondente\n",
    "        synsets_frame_annotations = get_synsets_frame_annotations(synsets_frame, synsets_frames_list_annotations)\n",
    "        \n",
    "        #check frame\n",
    "        evaluated = evaluated + 1\n",
    "        if synsets_frame_annotations.get_frame_synset() == synsets_frame.get_frame_synset():\n",
    "            checked = checked + 1\n",
    "        \n",
    "        #check frame elements\n",
    "        frame_elements_synsets_annotations = synsets_frame_annotations.get_frame_elements_synsets()\n",
    "        frame_elements_synsets = synsets_frame.get_frame_elements_synsets()\n",
    "        les_keys = frame_elements_synsets.keys()\n",
    "        for key in les_keys:\n",
    "            evaluated = evaluated + 1\n",
    "            if frame_elements_synsets[key] == frame_elements_synsets_annotations[key]:\n",
    "                checked = checked + 1\n",
    "        \n",
    "        #check lexical units\n",
    "        lexical_units_synsets_annotations = synsets_frame_annotations.get_lexical_units_synsets()\n",
    "        lexical_units_synsets = synsets_frame.get_lexical_units_synsets()\n",
    "        lus_keys = lexical_units_synsets.keys()\n",
    "        for key in lus_keys:\n",
    "            evaluated = evaluated + 1\n",
    "            if lexical_units_synsets[key] == lexical_units_synsets_annotations[key]:\n",
    "                checked = checked + 1\n",
    "                \n",
    "    print(\"\\nAccuratezza: \",format((checked/evaluated)*100,'.2f'),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08697f3-cc4d-4092-b4a4-ec1f137df40d",
   "metadata": {},
   "source": [
    "FUNZIONI PER LA VALUTAZIONE DEI RISULTATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bde5d6fd-cd6b-4c5a-91af-3e18cdaeb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restituisce una lista di ContextsFrame\n",
    "def get_contexts_frames_list(frames):\n",
    "    contexts_frames_list = []\n",
    "    for frame in frames:\n",
    "\n",
    "        #dati riguardanti i frame elements e le lexical units del frame\n",
    "        frame_elements_contexts = dict()\n",
    "        lexical_units_contexts = dict()\n",
    "        \n",
    "        FEs = frame.FE.keys()\n",
    "        for fe in FEs:\n",
    "            fed = frame.FE[fe]\n",
    "            frame_elements_contexts[fed.name] = context_for_frame_component(fed)\n",
    "            \n",
    "        LUs = frame.lexUnit.keys()\n",
    "        for lu in LUs:\n",
    "            lud = frame.lexUnit[lu]\n",
    "            lexical_units_contexts[lud.name] = context_for_frame_component(lud)\n",
    "        \n",
    "        contextsFrame = ContextsFrame(frame.ID, frame.name, context_for_frame(frame), frame_elements_contexts, lexical_units_contexts)\n",
    "        contexts_frames_list.append(contextsFrame) \n",
    "    return contexts_frames_list\n",
    "\n",
    "#Restituisce un senso di WordNet per il wordnet_name(frame name, frame element name, lexical unit name) che massimizza lo score\n",
    "def compute_score(wordnet_name, frameNet_context):\n",
    "    synsets = wn.synsets(wordnet_name)\n",
    "    if synsets == []: #se non ci sono synset disponibili\n",
    "        return None\n",
    "    #prende il synset con lo score più alto\n",
    "    max_score = 0\n",
    "    best_synset = synsets[0]\n",
    "    for synset in synsets:\n",
    "        synset_context = context_for_sense(synset)\n",
    "        score = get_score(frameNet_context,synset_context)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_synset = synset\n",
    "    return best_synset\n",
    "\n",
    "def get_score(context1,context2):\n",
    "    return len(context1.intersection(context2)) + 1\n",
    "    \n",
    "#Restituisce i risultati per quanto riguarda le associazioni di wordnet ai sensi di FrameNet\n",
    "#quindi restituisce una lista di oggetti SynsetsFrame\n",
    "#prende in input la lista di oggetti ContextsFrame che contiene i contesti dei\n",
    "#frame elements, lexical untis, frame name associati ad un frame\n",
    "def get_synsets_frames_list(contexts_frame_list):\n",
    "    synsets_frames_list = []\n",
    "    for contextsFrame in contexts_frame_list:\n",
    "        frame_id = contextsFrame.get_frame_id()\n",
    "        frame_name = contextsFrame.get_frame_name()\n",
    "        frame_synset = compute_score(get_regent(frame_name),contextsFrame.get_frame_context())\n",
    "        \n",
    "        frame_elements_synsets = dict()\n",
    "        lexical_units_synsets = dict()\n",
    "        \n",
    "        frame_elements_contexts = contextsFrame.get_frame_elements_contexts()\n",
    "        for frame_element_name in frame_elements_contexts:\n",
    "            #wordnet_name = get_regent(frame_element_name)\n",
    "            wordnet_name = frame_element_name\n",
    "            score = compute_score(wordnet_name, frame_elements_contexts[frame_element_name])\n",
    "            if not score is None:\n",
    "               frame_elements_synsets[frame_element_name] = score\n",
    "        \n",
    "        lexical_units_contexts = contextsFrame.get_lexical_units_contexts()\n",
    "        for lexical_unit_name in lexical_units_contexts:\n",
    "            wordnet_name = remove_pos_lu(lexical_unit_name)\n",
    "            score = compute_score(wordnet_name, lexical_units_contexts[lexical_unit_name])\n",
    "            if not score is None:\n",
    "                lexical_units_synsets[lexical_unit_name] = score\n",
    "    \n",
    "        synsetsFrame = SynsetsFrame(frame_id, frame_name, frame_synset, frame_elements_synsets, lexical_units_synsets)\n",
    "        synsets_frames_list.append(synsetsFrame)\n",
    "    return synsets_frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8391ed5c-7e55-4eed-816b-e9c7c8c351f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COGNOME STUDENTE: Parisi\n",
      "\n",
      "\n",
      "RISULTATI SISTEMA:\n",
      " \n",
      "FRAME ID:  264\n",
      "FRAME NAME:  Sleep\n",
      "FRAME SYNSET:  Synset('sleep.n.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Sleeper': Synset('sleeper.n.01'), 'Duration': Synset('duration.n.01'), 'Time': Synset('time.n.01'), 'Place': Synset('topographic_point.n.01'), 'Degree': Synset('degree.n.01'), 'Manner': Synset('manner.n.01')}\n",
      "LEXICAL UNITS SYNSETS:  {'nap.v': Synset('nap.v.01'), 'doze.v': Synset('snooze.v.01'), 'snooze.v': Synset('nap.n.04'), 'catnap.v': Synset('nap.n.04'), 'slumber.v': Synset('sleep.n.01'), 'hibernate.v': Synset('hibernate.v.01'), 'kip.v': Synset('kip.n.01'), 'drowse.v': Synset('drowse.v.02'), 'sleep.v': Synset('sleep.n.01'), 'doze.n': Synset('doze.n.01'), 'catnap.n': Synset('nap.n.04'), 'drowse.n': Synset('drowse.v.02'), 'hibernation.n': Synset('hibernation.n.01'), 'kip.n': Synset('kip.n.01'), 'nap.n': Synset('nap.n.04'), 'sleep [event].n': Synset('sleep.n.01'), 'slumber.n': Synset('sleep.n.01'), 'snooze.n': Synset('nap.n.04'), 'asleep.a': Synset('asleep.a.01'), 'sleep [quantity].n': Synset('sleep.n.03'), 'out.a': Synset('knocked_out.s.01'), 'unconscious.a': Synset('unconscious_mind.n.01')}\n",
      "------------------------------\n",
      "FRAME ID:  2723\n",
      "FRAME NAME:  Be_on_alert\n",
      "FRAME SYNSET:  Synset('alert.n.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Protagonist': Synset('supporter.n.01'), 'Activity': Synset('bodily_process.n.01'), 'Time': Synset('time.n.01'), 'Result': Synset('consequence.n.01'), 'Duration': Synset('duration.n.03'), 'Degree': Synset('degree.n.01'), 'Danger': Synset('danger.n.01')}\n",
      "LEXICAL UNITS SYNSETS:  {'alert.n': Synset('alert.n.01'), 'guard.n': Synset('precaution.n.01')}\n",
      "------------------------------\n",
      "FRAME ID:  1441\n",
      "FRAME NAME:  Rising_to_a_challenge\n",
      "FRAME SYNSET:  Synset('challenge.n.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Protagonist': Synset('supporter.n.01'), 'Activity': Synset('activity.n.01'), 'Degree': Synset('degree.n.02'), 'Circumstances': Synset('fortune.n.04'), 'Explanation': Synset('explanation.n.01'), 'Means': Synset('means.n.01'), 'Time': Synset('time.n.01'), 'Place': Synset('position.n.06'), 'Manner': Synset('manner.n.01')}\n",
      "LEXICAL UNITS SYNSETS:  {'rise.v': Synset('rise.n.01')}\n",
      "------------------------------\n",
      "FRAME ID:  1690\n",
      "FRAME NAME:  Use_vehicle\n",
      "FRAME SYNSET:  Synset('vehicle.n.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Theme': Synset('subject.n.01'), 'Vehicle': Synset('vehicle.n.01'), 'Source': Synset('generator.n.03'), 'Manner': Synset('manner.n.01'), 'Path': Synset('path.n.03'), 'Goal': Synset('goal.n.01'), 'Distance': Synset('distance.n.01'), 'Duration': Synset('duration.n.01'), 'Speed': Synset('speed.n.01'), 'Area': Synset('area.n.01'), 'Road': Synset('road.n.01'), 'Route': Synset('path.n.03'), 'Time': Synset('time.n.01'), 'Driver': Synset('driver.n.01')}\n",
      "LEXICAL UNITS SYNSETS:  {}\n",
      "------------------------------\n",
      "FRAME ID:  363\n",
      "FRAME NAME:  Deciding\n",
      "FRAME SYNSET:  Synset('decide.v.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Decision': Synset('decision.n.01'), 'Possibilities': Synset('possibility.n.01'), 'Time': Synset('prison_term.n.01'), 'Place': Synset('topographic_point.n.01'), 'Manner': Synset('manner.n.01'), 'Circumstance': Synset('circumstance.n.01'), 'Explanation': Synset('explanation.n.01')}\n",
      "LEXICAL UNITS SYNSETS:  {'decide.v': Synset('decide.v.02'), 'decision.n': Synset('decision.n.02'), 'determine.v': Synset('determine.v.02')}\n",
      "------------------------------\n",
      "\n",
      "\n",
      "ANNOTAZIONI UMANE:\n",
      " \n",
      "FRAME ID:  264\n",
      "FRAME NAME:  Sleep\n",
      "FRAME SYNSET:  Synset('sleep.v.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Sleeper': Synset('sleeper.n.01'), 'Degree': Synset('degree.n.05'), 'Duration': Synset('duration.n.03'), 'Manner': Synset('manner.n.01')}\n",
      "LEXICAL UNITS SYNSETS:  {'asleep.n': Synset('sleep.n.01'), 'slumber.v': Synset('sleep.v.01'), 'snooze.n': Synset('nap.n.04'), 'snooze.v': Synset('nap.v.01'), 'catnap.n': Synset('nap.n.04'), 'doze.n': Synset('doze.n.01')}\n",
      "------------------------------\n",
      "FRAME ID:  2723\n",
      "FRAME NAME:  Be_on_alert\n",
      "FRAME SYNSET:  Synset('alert.n.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Activity': Synset('activity.n.01'), 'Danger': Synset('danger.n.01'), 'Protagonist': Synset('supporter.n.01'), 'Time': Synset('time.n.06'), 'Degree': Synset('degree.n.05'), 'Duration': Synset('duration.n.03')}\n",
      "LEXICAL UNITS SYNSETS:  {'alert.n': Synset('sleep.n.01'), 'guard.n': Synset('sleep.n.01')}\n",
      "------------------------------\n",
      "FRAME ID:  1441\n",
      "FRAME NAME:  Rising_to_a_challenge\n",
      "FRAME SYNSET:  Synset('challenge.n.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Activity': Synset('activity.n.01'), 'Protagonist': Synset('supporter.n.01'), 'Degree': Synset('degree.n.02'), 'Explanation': Synset('explanation.n.01'), 'Place': Synset('place.n.06'), 'Circumstances': Synset('fortune.n.04')}\n",
      "LEXICAL UNITS SYNSETS:  {'rise to the occasion.v': Synset('originate.v.01'), 'rise.v': Synset('originate.v.01')}\n",
      "------------------------------\n",
      "FRAME ID:  1690\n",
      "FRAME NAME:  Use_vehicle\n",
      "FRAME SYNSET:  Synset('vehicle.n.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Area': Synset('area.n.01'), 'Driver': Synset('driver.n.01'), 'Goal': Synset('goal.n.01'), 'Path': Synset('way.n.05'), 'Source': Synset('beginning.n.04'), 'Theme': Synset('subject.n.01'), 'Vehicle': Synset('vehicle.n.01'), 'Road': Synset('road.n.01')}\n",
      "LEXICAL UNITS SYNSETS:  {}\n",
      "------------------------------\n",
      "FRAME ID:  363\n",
      "FRAME NAME:  Deciding\n",
      "FRAME SYNSET:  Synset('decide.v.01')\n",
      "FRAME ELEMENTS SYNSETS:  {'Cognizer': Synset('decision.n.01'), 'Decision': Synset('decision.n.01'), 'Circumstance': Synset('fortune.n.04'), 'Explanation': Synset('explanation.n.01'), 'Inherent_purpose': Synset('determination.n.02'), 'Manner': Synset('manner.n.02'), 'Place': Synset('topographic_point.n.01')}\n",
      "LEXICAL UNITS SYNSETS:  {'decide.v': Synset('decide.v.01'), 'decision.n': Synset('decision.n.01'), 'determine.v': Synset('determine.v.01')}\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4f69596aedb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtotal_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynsets_frames_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msynsets_frames_list_annotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-4f69596aedb1>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mtotal_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynsets_frames_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msynsets_frames_list_annotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-36d0cef43525>\u001b[0m in \u001b[0;36mtotal_accuracy\u001b[1;34m(synsets_frames_list, synsets_frames_list_annotations)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mles_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mevaluated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mframe_elements_synsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mframe_elements_synsets_annotations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0mchecked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchecked\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Time'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    #Lista di oggetti di tipo ContextsFrame(vedere ContextsFrame)\n",
    "    contexts_frames_list = get_contexts_frames_list(getFrameSetForStudent(SURNAME))\n",
    "\n",
    "    #Lista di oggetti di tipo SynsetsFrame (vedere Synsetsframe)\n",
    "    synsets_frames_list = get_synsets_frames_list(contexts_frames_list)\n",
    "    \n",
    "    print(\"\\nRISULTATI SISTEMA:\\n \")\n",
    "    for item in synsets_frames_list:\n",
    "        item.printSynsetsFrame()\n",
    "    \n",
    "    #Lista di oggetti di tipo SynsetsFrame (ma riguarda le annotazioni umane)\n",
    "    synsets_frames_list_annotations = get_synsets_frames_list_annotations()\n",
    "    \n",
    "    print(\"\\n\\nANNOTAZIONI UMANE:\\n \")\n",
    "    for item in synsets_frames_list_annotations:\n",
    "        item.printSynsetsFrame()\n",
    "    \n",
    "    #testing\n",
    "    total_accuracy(synsets_frames_list, synsets_frames_list_annotations)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
