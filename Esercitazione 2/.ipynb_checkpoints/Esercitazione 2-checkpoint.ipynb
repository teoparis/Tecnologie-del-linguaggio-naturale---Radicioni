{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d193f124-fa2a-4a00-b3d6-f80910727f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import hashlib\n",
    "import spacy\n",
    "from random import randint\n",
    "from random import seed\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3929cf7-9127-49ed-a462-36582fbed7ac",
   "metadata": {},
   "source": [
    "FUNZIONI DI PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37821d28-7d95-4d3b-b14d-35b6186fbfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#il pre-processing consiste nella tokenizzazione, lemmatizzazione,\n",
    "#rimozione della punteggiatura e delle stopwords di una sentence\n",
    "def pre_processing(sentence):\n",
    "    return set(remove_stopwords(tokenize_sentence(remove_punctuation(sentence))))\n",
    "\n",
    "#Effettua la lemmatizzazione e rimuove le stowords da una lista di parole\n",
    "def remove_stopwords(words_list):\n",
    "    stopwords_list = get_stopwords()\n",
    "    return [value for value in words_list if value not in stopwords_list]\n",
    "\n",
    "\n",
    "#Tokenizza la frase in input e ne affettua anche la lemmatizzazione della sue parole\n",
    "def tokenize_sentence(sentence):\n",
    "    words_list = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        if (tag[1][:2] == \"NN\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos = wn.NOUN))\n",
    "        elif (tag[1][:2] == \"VB\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.VERB))\n",
    "        elif (tag[1][:2] == \"RB\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.ADV))\n",
    "        elif (tag[1][:2] == \"JJ\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.ADJ))\n",
    "    return words_list\n",
    "\n",
    "#Restituisce la l'insieme di stopwords dal file delle stopwords\n",
    "def get_stopwords():\n",
    "    stopwords = open(\"stop_words_FULL.txt\", \"r\")\n",
    "    stopwords_list = []\n",
    "    for word in stopwords:\n",
    "        stopwords_list.append(word.replace('\\n', ''))\n",
    "    stopwords.close()\n",
    "    return stopwords_list\n",
    "\n",
    "#Rimuove la punteggiatura da una sentence\n",
    "#Restituisce la sentence senza punteggiature\n",
    "def remove_punctuation(sentence):\n",
    "    return re.sub(r'[^\\w\\s]','',sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c2efc-fd57-48a1-86fb-324d3012562d",
   "metadata": {},
   "source": [
    "FUNZIONI UTILI PER IL RITROVAMENTO DEI FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbb14c6-b9c4-4d75-818f-f1623a010ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contesti associati ad un Frame. Struttura dati che contiene\n",
    "#i contesti associati al frame, ai suoi frame elements e alle sue\n",
    "#lexical units\n",
    "class ContextsFrame:\n",
    "    \n",
    "    def __init__(self, frame_id, frame_name, frame_context,\n",
    "                 frame_elements_contexts, lexical_units_contexts):\n",
    "        self.frame_id = frame_id\n",
    "        self.frame_name = frame_name\n",
    "        self.frame_context = frame_context\n",
    "        #dizionario: [frame_element_name] -> context\n",
    "        self.frame_elements_contexts = frame_elements_contexts\n",
    "        \n",
    "        #dizionario: [lexical_unit_name] -> context\n",
    "        self.lexical_units_contexts = lexical_units_contexts\n",
    "        \n",
    "    def get_frame_elements_contexts(self):\n",
    "        return self.frame_elements_contexts\n",
    "    def get_lexical_units_contexts(self):\n",
    "        return self.lexical_units_contexts\n",
    "    def get_frame_id(self):\n",
    "        return self.frame_id\n",
    "    def get_frame_name(self):\n",
    "        return self.frame_name\n",
    "    def get_frame_context(self):\n",
    "        return self.frame_context\n",
    "    #stampa fatta al solo scopo di conoscere le struttura interna della classe\n",
    "    def printContextsFrame(self):\n",
    "        print(\"FRAME ID: \", self.get_frame_id())\n",
    "        print(\"FRAME NAME: \",self.get_frame_name())\n",
    "        print(\"\\nFRAME CONTEXT: \",\"\\n\",self.get_frame_context())\n",
    "        print(\"\\nFRAME ELEMENTS CONTEXTS: \",\"\\n\", self.get_frame_elements_contexts())\n",
    "        print(\"\\nLEXICAL UNITS CONTEXTS: \",\"\\n\", self.get_lexical_units_contexts())\n",
    "        print(\"_________________________________________\")\n",
    "        \n",
    "    \n",
    "#Risultati di WordNet.\n",
    "#Struttura che contiene i synset associati al frame in questione\n",
    "#ai suoi frame elements e alle sue lexical_units\n",
    "#Questi risultati dovranno poi essere confrontati con \n",
    "#annotazioni fatte degli umani\n",
    "#quindi ogni annotazione per ogni frame dovrà essere di questo tipo\n",
    "#e.s SynsetsFrameAnnotation\n",
    "class SynsetsFrame:\n",
    "    def __init__(self, frame_id, frame_name, frame_synset,\n",
    "                 frame_elements_synsets, lexical_units_synsets):\n",
    "        self.frame_id = frame_id\n",
    "        self.frame_name = frame_name\n",
    "        self.frame_synset = frame_synset\n",
    "        self.frame_elements_synsets = frame_elements_synsets\n",
    "        self.lexical_units_synsets = lexical_units_synsets\n",
    "    def get_frame_elements_synsets(self):\n",
    "        return self.frame_elements_synsets\n",
    "    def get_lexical_units_synsets(self):\n",
    "        return self.lexical_units_synsets\n",
    "    def get_frame_id(self):\n",
    "        return self.frame_id\n",
    "    def get_frame_name(self):\n",
    "        return self.frame_name\n",
    "    def get_frame_synset(self):\n",
    "        return self.frame_synset\n",
    "    #stampa fatta al solo scopo di conoscere le struttura interna della classe\n",
    "    def printSynsetsFrame(self):\n",
    "        print(\"FRAME ID: \", self.get_frame_id())\n",
    "        print(\"FRAME NAME: \",self.get_frame_name())\n",
    "        print(\"\\nFRAME SYNSET: \",self.get_frame_synset())\n",
    "        print(\"\\nFRAME ELEMENTS SYNSETS: \",\"\\n\", self.get_frame_elements_synsets())\n",
    "        print(\"\\nLEXICAL UNITS SYNSETS: \",\"\\n\", self.get_lexical_units_synsets())\n",
    "        print(\"_________________________________________\")\n",
    "\n",
    "#-----------------------FUNZIONI DEL PROF---------------------------#\n",
    "def print_frames_with_IDs():\n",
    "    for x in fn.frames():\n",
    "        print('{}\\t{}'.format(x.ID, x.name))\n",
    "\n",
    "def get_frams_IDs():\n",
    "    return [f.ID for f in fn.frames()]   \n",
    "\n",
    "#restituisce un insieme di 5 frame legati allo studente in input ('Altamura')\n",
    "def getFrameSetForStudent(surname, list_len=5):\n",
    "    nof_frames = len(fn.frames())\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % nof_frames)\n",
    "    print('\\nstudent: ' + surname + \"\\n\")\n",
    "    framenet_IDs = get_frams_IDs()\n",
    "    i = 0\n",
    "    offset = 0 \n",
    "    seed(1)\n",
    "    frame_list = []\n",
    "    while i < list_len:\n",
    "        fID = framenet_IDs[(base_idx+offset)%nof_frames]\n",
    "        f = fn.frame(fID)\n",
    "        frame_list.append(fn.frame(fID))\n",
    "        fNAME = f.name\n",
    "        #print('\\tID: {a:4d}\\tframe: {framename}'.format(a=fID, framename=fNAME))\n",
    "        offset = randint(0, nof_frames)\n",
    "        i += 1\n",
    "    return frame_list        \n",
    "#-----------------------FUNZIONI DEL PROF---------------------------#\n",
    "\n",
    "#Prende in input un frame di FrameNet e restituisce il suo contesto\n",
    "#formato da tutte le definizioni dei suoi frame element, lexical unit\n",
    "#e del frame stesso. Le frasi sono tutte pre-processate\n",
    "#in modo tale da ottenere un set di parole lemmatizzate, senza stopwords\n",
    "#senza punteggiatura\n",
    "def context_for_frame(frame):\n",
    "    context_frame = set()\n",
    "    \n",
    "    context_frame.update(pre_processing(frame.definition))\n",
    "    \n",
    "    FEs = frame.FE.keys()\n",
    "    for fe in FEs:\n",
    "        fed = frame.FE[fe]\n",
    "        context_frame.update(pre_processing(fed.definition))\n",
    "    \n",
    "    LUs = frame.lexUnit.keys()\n",
    "    for lu in LUs:\n",
    "        lud = frame.lexUnit[lu]\n",
    "        context_frame.update(pre_processing(lud.definition))\n",
    "    \n",
    "    return context_frame\n",
    "\n",
    "#Restituisce il contesto per un frame component (frame element o lexical unit)\n",
    "#che è praticamente formato dalla sua definizione, lemmatizzata,\n",
    "#da cui sono state rimosse le stop words e punteggiatura\n",
    "def context_for_frame_component(frame_component):\n",
    "    context_frame_component = set()\n",
    "    \n",
    "    context_frame_component.update(pre_processing(frame_component.definition))\n",
    "    \n",
    "    return context_frame_component\n",
    "\n",
    "#Prende in input un senso di WordNet e restituisce il suo contesto\n",
    "#formato da tutte le definizioni ed esempi dei suoi iperonimi, iponimi\n",
    "# e definizione ed esempi del senso stesso. Le frasi sono tutte pre-processate\n",
    "#in modo tale da ottenere un set di parole lemmatizzate, senza stopwords\n",
    "#senza punteggiatura\n",
    "def context_for_sense(sense):\n",
    "    context_sense = set()\n",
    "    \n",
    "    context_sense.update(pre_processing(sense.definition()))\n",
    "    for example in sense.examples():\n",
    "        context_sense.update(pre_processing(example))\n",
    "    \n",
    "    for hypernym in sense.hypernyms():\n",
    "        context_sense.update(pre_processing(hypernym.definition()))\n",
    "        for example in hypernym.examples():\n",
    "            context_sense.update(pre_processing(example))\n",
    "            \n",
    "    for hyponym in sense.hyponyms():\n",
    "        context_sense.update(pre_processing(hyponym.definition()))\n",
    "        for example in hyponym.examples():\n",
    "            context_sense.update(pre_processing(example))\n",
    "    return context_sense\n",
    "\n",
    "#riceve in input una frase semplice(costituita da circa due parole separate da _)\n",
    "#e restituisce in output il reggente della frase\n",
    "def get_regent(sentence):\n",
    "    \n",
    "    if sentence == 'Process_stopped_state':\n",
    "        return 'stopped'\n",
    "    elif sentence == 'Transitive_action':\n",
    "        return 'action'\n",
    "    elif sentence == 'Personal_success':\n",
    "        return 'success'\n",
    "    elif sentence == 'Scrutinizing_for':\n",
    "        return 'scrutinizing'\n",
    "    elif sentence == 'Cache':\n",
    "        return 'cache'\n",
    "\n",
    "#Le unità lessicali ricavate da FrameNet per un determinato frame sono nella forma <ul>.PoS (esempio: before.prep)\n",
    "#pertanto, per poter individuare il senso o i sensi corrispondenti all'unità lessicale, è importante rimuovere\n",
    "#il punto e il PoS che segue\n",
    "def remove_pos_lu(lexical_unit_name):\n",
    "    new_lexical_unit_name = lexical_unit_name.split(\".\")[0]\n",
    "    \n",
    "    #Remove [...] from lexical_unit_name\n",
    "    return new_lexical_unit_name.split(\" [\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532654bb-88d3-4c89-8ae9-b576cab55273",
   "metadata": {},
   "source": [
    "FUNZIONI PER LA VALUTAZIONE DEI RISULTATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8fabc13-c6a8-4dad-9b8e-de0f31a00bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restituisce un oggetto SynsetsFrame della lista synsets_frames_list_annotations\n",
    "#con lo stesso frame_id dell'oggetto SynsetsFrame synsets_frame\n",
    "def get_synsets_frame_annotations(synsets_frame,synsets_frames_list_annotations):\n",
    "    for synsets_frame_annotations in synsets_frames_list_annotations:\n",
    "        if synsets_frame_annotations.get_frame_id() == synsets_frame.get_frame_id():\n",
    "            return synsets_frame_annotations\n",
    "\n",
    "def total_accuracy(synsets_frames_list, synsets_frames_list_annotations):\n",
    "    evaluated = 0\n",
    "    checked = 0\n",
    "    for synsets_frame in synsets_frames_list:\n",
    "        #prendo l'oggetto SynsetsFrame corrispondente\n",
    "        synsets_frame_annotations = get_synsets_frame_annotations(synsets_frame, synsets_frames_list_annotations)\n",
    "        \n",
    "        \n",
    "        #check frame\n",
    "        evaluated = evaluated + 1\n",
    "        if synsets_frame_annotations.get_frame_synset() == synsets_frame.get_frame_synset():\n",
    "            checked = checked + 1\n",
    "        \n",
    "        #check frame elements\n",
    "        frame_elements_synsets_annotations = synsets_frame_annotations.get_frame_elements_synsets()\n",
    "        frame_elements_synsets = synsets_frame.get_frame_elements_synsets()\n",
    "        les_keys = frame_elements_synsets.keys()\n",
    "        for key in les_keys:\n",
    "            evaluated = evaluated + 1\n",
    "            if frame_elements_synsets[key] == frame_elements_synsets_annotations[key]:\n",
    "                checked = checked + 1\n",
    "        \n",
    "        #check lexical units\n",
    "        lexical_units_synsets_annotations = synsets_frame_annotations.get_lexical_units_synsets()\n",
    "        lexical_units_synsets = synsets_frame.get_lexical_units_synsets()\n",
    "        lus_keys = lexical_units_synsets.keys()\n",
    "        for key in lus_keys:\n",
    "            evaluated = evaluated + 1\n",
    "            if lexical_units_synsets[key] == lexical_units_synsets_annotations[key]:\n",
    "                checked = checked + 1\n",
    "                \n",
    "    print(\"Accuratezza: \",format((checked/evaluated)*100,'.2f'),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b3134-5816-4e57-beea-e1e77f3c40c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb4d0d2-6dc5-4831-86bb-be272eac1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "student: Altamura\n",
    "\tID:  153\t      frame: Process_stopped_state\n",
    "\tID:   10      frame: Transitive_action\n",
    "\tID: 2411    \t  frame: Personal_success\n",
    "\tID: 1684    \t  frame: Scrutinizing_for\n",
    "\tID: 2576\t      frame: Cache\n",
    "\"\"\"\n",
    "\n",
    "def get_synsets_frames_list_annotations():\n",
    "    \n",
    "    synsets_frames_list_annotations = []\n",
    "    \n",
    "    #-------------------------------------------------------------#\n",
    "    frame_id_1 = 153\n",
    "    frame_name_1 = 'Process_stopped_state'\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_1 = wn.synset('discontinue.v.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_1 = dict()\n",
    "    frame_elements_synsets_1['Process'] = wn.synset('process.n.06')\n",
    "    frame_elements_synsets_1['Time'] = wn.synset('time.n.01')\n",
    "    frame_elements_synsets_1['Duration'] = wn.synset('duration.n.03')\n",
    "    \n",
    "    #LUs\n",
    "    lexical_units_synsets_1 = dict()\n",
    "    \n",
    "    synsets_frame_1 = SynsetsFrame(frame_id_1, frame_name_1, frame_synset_1, \n",
    "                                       frame_elements_synsets_1, lexical_units_synsets_1)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_1)\n",
    "    \n",
    "    #-------------------------------------------------------------#\n",
    "    frame_id_2 = 10\n",
    "    frame_name_2 = \"Transitive_action\"\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_2 = wn.synset('action.n.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_2 = dict()\n",
    "    frame_elements_synsets_2['Agent'] = wn.synset('agent.n.02')\n",
    "    frame_elements_synsets_2['Patient'] = wn.synset('affected_role.n.01')\n",
    "    frame_elements_synsets_2['Event'] = wn.synset('event.n.01')\n",
    "    frame_elements_synsets_2['Depictive'] = wn.synset('delineative.s.01')\n",
    "    frame_elements_synsets_2['Result'] = wn.synset('consequence.n.01')\n",
    "    frame_elements_synsets_2['Means'] = wn.synset('means.n.02')\n",
    "    frame_elements_synsets_2['Manner'] = wn.synset('manner.n.01')\n",
    "    frame_elements_synsets_2['Time'] = wn.synset('time.n.01')\n",
    "    frame_elements_synsets_2['Place'] = wn.synset('place.n.02')\n",
    "    frame_elements_synsets_2['Cause'] = wn.synset('cause.n.01')\n",
    "    \n",
    "    #LUs\n",
    "    lexical_units_synsets_2 = dict()\n",
    "    \n",
    "    synsets_frame_2 = SynsetsFrame(frame_id_2, frame_name_2, frame_synset_2, \n",
    "                                       frame_elements_synsets_2, lexical_units_synsets_2)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_2)\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------#\n",
    "    \n",
    "    frame_id_3 = 2411\n",
    "    frame_name_3 = \"Personal_success\"\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_3 = wn.synset('success.n.02')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_3 = dict()\n",
    "    frame_elements_synsets_3['Person'] = wn.synset('person.n.01')\n",
    "    frame_elements_synsets_3['Time'] = wn.synset('time.n.02')\n",
    "    frame_elements_synsets_3['Degree'] = wn.synset('degree.n.02')\n",
    "    frame_elements_synsets_3['Endeavor'] = wn.synset('attempt.n.01')\n",
    "    frame_elements_synsets_3['Explanation'] = wn.synset('explanation.n.01')\n",
    "    frame_elements_synsets_3['Field'] = wn.synset('discipline.n.01')\n",
    "    \n",
    "    #LUs\n",
    "    lexical_units_synsets_3 = dict()\n",
    "    lexical_units_synsets_3['success [person].n'] = wn.synset('achiever.n.01')\n",
    "    lexical_units_synsets_3['success [event].n'] = wn.synset('success.n.01')\n",
    "    lexical_units_synsets_3['success [state].n'] = wn.synset('success.n.03')\n",
    "    lexical_units_synsets_3['successful.a'] = wn.synset('successful.a.01')\n",
    "    lexical_units_synsets_3['arrive.v'] = wn.synset('arrive.v.02')\n",
    "    lexical_units_synsets_3['succeed.v'] = wn.synset('succeed.v.01')\n",
    "    \n",
    "    synsets_frame_3 = SynsetsFrame(frame_id_3, frame_name_3, frame_synset_3, \n",
    "                                       frame_elements_synsets_3, lexical_units_synsets_3)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_3)\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------#\n",
    "    frame_id_4 = 1684\n",
    "    frame_name_4 = 'Scrutinizing_for'\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_4 = wn.synset('size_up.v.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_4 = dict()\n",
    "    frame_elements_synsets_4['Ground'] = wn.synset('ground.n.08')\n",
    "    frame_elements_synsets_4['Phenomenon'] = wn.synset('phenomenon.n.01')\n",
    "    frame_elements_synsets_4['Manner'] = wn.synset('manner.n.01')\n",
    "    frame_elements_synsets_4['Means'] = wn.synset('means.n.01')\n",
    "    frame_elements_synsets_4['Degree'] = wn.synset('degree.n.02')\n",
    "    frame_elements_synsets_4['Purpose'] = wn.synset('purpose.n.01')\n",
    "    frame_elements_synsets_4['Instrument'] = wn.synset('instrumental_role.n.01')\n",
    "    \n",
    "    #LUs\n",
    "    lexical_units_synsets_4 = dict()\n",
    "    \n",
    "    synsets_frame_4 = SynsetsFrame(frame_id_4, frame_name_4, frame_synset_4, \n",
    "                                       frame_elements_synsets_4, lexical_units_synsets_4)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_4)\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------#\n",
    "    \n",
    "    frame_id_5 = 2576\n",
    "    frame_name_5 = 'Cache'\n",
    "    \n",
    "    #Frame_name\n",
    "    frame_synset_5 = wn.synset('hoard.n.01')\n",
    "    \n",
    "    #FEs\n",
    "    frame_elements_synsets_5 = dict()\n",
    "    frame_elements_synsets_5['Cache'] = wn.synset('hoard.n.01')\n",
    "    frame_elements_synsets_5['Resource'] = wn.synset('resource.n.01')\n",
    "    frame_elements_synsets_5['Use'] = wn.synset('use.v.01')\n",
    "    frame_elements_synsets_5['Possessor'] = wn.synset('owner.n.02')\n",
    "    frame_elements_synsets_5['Descriptor'] = wn.synset('descriptor.n.02')\n",
    "    \n",
    "    #LUs\n",
    "    lexical_units_synsets_5 = dict()\n",
    "    lexical_units_synsets_5['cache.n'] = wn.synset('hoard.n.01')\n",
    "    lexical_units_synsets_5['stash.n'] = wn.synset('hoard.n.01')\n",
    "    \n",
    "    synsets_frame_5 = SynsetsFrame(frame_id_5, frame_name_5, frame_synset_5, \n",
    "                                       frame_elements_synsets_5, lexical_units_synsets_5)\n",
    "    \n",
    "    synsets_frames_list_annotations.append(synsets_frame_5)\n",
    "    \n",
    "    return synsets_frames_list_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08697f3-cc4d-4092-b4a4-ec1f137df40d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bde5d6fd-cd6b-4c5a-91af-3e18cdaeb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "SURNAME = 'Altamura'\n",
    "\n",
    "#Restituisce una lista di ContextsFrame\n",
    "def get_contexts_frames_list(frames):\n",
    "    contexts_frames_list = []\n",
    "    for frame in frames:\n",
    "      \n",
    "        #dati riguardanti i frame elements e le lexical units del frame\n",
    "        frame_elements_contexts = dict()\n",
    "        lexical_units_contexts = dict()\n",
    "        \n",
    "        FEs = frame.FE.keys()\n",
    "        for fe in FEs:\n",
    "            fed = frame.FE[fe]\n",
    "            frame_elements_contexts[fed.name] = context_for_frame_component(fed)\n",
    "            \n",
    "        LUs = frame.lexUnit.keys()\n",
    "        for lu in LUs:\n",
    "            lud = frame.lexUnit[lu]\n",
    "            lexical_units_contexts[lud.name] = context_for_frame_component(lud)\n",
    "        \n",
    "        contextsFrame = ContextsFrame(frame.ID, frame.name, context_for_frame(frame), \n",
    "                                            frame_elements_contexts, lexical_units_contexts)\n",
    "        contexts_frames_list.append(contextsFrame) \n",
    "    return contexts_frames_list\n",
    "\n",
    "#restituisce un senso di WordNet per il wordnet_name(frame name, frame element name, lexical unit name)\n",
    "#che massimizza lo score\n",
    "def compute_score(wordnet_name, frameNet_context):\n",
    "    synsets = wn.synsets(wordnet_name)\n",
    "    if synsets == []: #se non ci sono synset disponibili\n",
    "        return None\n",
    "    #prende il synset con lo score più alto\n",
    "    max_score = 0\n",
    "    best_synset = synsets[0]\n",
    "    for synset in synsets:\n",
    "        synset_context = context_for_sense(synset)\n",
    "        score = get_score(frameNet_context,synset_context)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_synset = synset\n",
    "    return best_synset\n",
    "\n",
    "def get_score(context1,context2):\n",
    "    return len(context1.intersection(context2)) + 1\n",
    "    \n",
    "#Restituisce i risultati per quanto riguarda le associazioni di wordnet ai sensi di FrameNet\n",
    "#quindi restituisce una lista di oggetti SynsetsFrame\n",
    "#prende in input la lista di oggetti ContextsFrame che contiene i contesti dei\n",
    "#frame elements, lexical untis, frame name associati ad un frame\n",
    "def get_synsets_frames_list(contexts_frame_list):\n",
    "    synsets_frames_list = []\n",
    "    for contextsFrame in contexts_frame_list:\n",
    "        frame_id = contextsFrame.get_frame_id()\n",
    "        frame_name = contextsFrame.get_frame_name()\n",
    "        frame_synset = compute_score(get_regent(frame_name),\n",
    "                                     contextsFrame.get_frame_context())\n",
    "        \n",
    "        frame_elements_synsets = dict()\n",
    "        lexical_units_synsets = dict()\n",
    "        \n",
    "        frame_elements_contexts = contextsFrame.get_frame_elements_contexts()\n",
    "        for frame_element_name in frame_elements_contexts:\n",
    "            #wordnet_name = get_regent(frame_element_name)\n",
    "            wordnet_name = frame_element_name\n",
    "            score = compute_score(wordnet_name, frame_elements_contexts[frame_element_name])\n",
    "            if not score is None:\n",
    "               frame_elements_synsets[frame_element_name] = score\n",
    "        \n",
    "        lexical_units_contexts = contextsFrame.get_lexical_units_contexts()\n",
    "        for lexical_unit_name in lexical_units_contexts:\n",
    "            wordnet_name = remove_pos_lu(lexical_unit_name)\n",
    "            score = compute_score(wordnet_name, lexical_units_contexts[lexical_unit_name])\n",
    "            if not score is None:\n",
    "                lexical_units_synsets[lexical_unit_name] = score\n",
    "    \n",
    "        synsetsFrame = SynsetsFrame(frame_id, frame_name, frame_synset, frame_elements_synsets, lexical_units_synsets)\n",
    "        synsets_frames_list.append(synsetsFrame)\n",
    "    return synsets_frames_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0313c144-08dd-4f21-8239-3d2d952b2afa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8391ed5c-7e55-4eed-816b-e9c7c8c351f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "student: Altamura\n",
      "\n",
      "=========================\n",
      "RISULTATI SISTEMA: \n",
      "FRAME ID:  153\n",
      "FRAME NAME:  Process_stopped_state\n",
      "\n",
      "FRAME SYNSET:  Synset('discontinue.v.01')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Process': Synset('process.n.06'), 'Time': Synset('time.n.03'), 'Duration': Synset('duration.n.03')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {}\n",
      "_________________________________________\n",
      "FRAME ID:  10\n",
      "FRAME NAME:  Transitive_action\n",
      "\n",
      "FRAME SYNSET:  Synset('action.n.01')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Agent': Synset('agent.n.01'), 'Patient': Synset('affected_role.n.01'), 'Event': Synset('event.n.03'), 'Depictive': Synset('delineative.s.01'), 'Result': Synset('consequence.n.01'), 'Means': Synset('means.n.01'), 'Manner': Synset('manner.n.01'), 'Time': Synset('time.n.01'), 'Place': Synset('topographic_point.n.01'), 'Cause': Synset('cause.n.01')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {}\n",
      "_________________________________________\n",
      "FRAME ID:  2411\n",
      "FRAME NAME:  Personal_success\n",
      "\n",
      "FRAME SYNSET:  Synset('success.n.02')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Person': Synset('person.n.01'), 'Time': Synset('time.n.02'), 'Degree': Synset('degree.n.02'), 'Endeavor': Synset('enterprise.n.01'), 'Explanation': Synset('explanation.n.01'), 'Field': Synset('field.n.01')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {'success [person].n': Synset('achiever.n.01'), 'success [event].n': Synset('achiever.n.01'), 'success [state].n': Synset('success.n.03'), 'successful.a': Synset('successful.a.01'), 'arrive.v': Synset('arrive.v.01'), 'succeed.v': Synset('succeed.v.01')}\n",
      "_________________________________________\n",
      "FRAME ID:  1684\n",
      "FRAME NAME:  Scrutinizing_for\n",
      "\n",
      "FRAME SYNSET:  Synset('size_up.v.01')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Ground': Synset('land.n.04'), 'Phenomenon': Synset('phenomenon.n.01'), 'Manner': Synset('manner.n.01'), 'Means': Synset('means.n.01'), 'Degree': Synset('degree.n.01'), 'Purpose': Synset('purpose.n.01'), 'Instrument': Synset('instrument.n.02')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {}\n",
      "_________________________________________\n",
      "FRAME ID:  2576\n",
      "FRAME NAME:  Cache\n",
      "\n",
      "FRAME SYNSET:  Synset('hoard.n.01')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Cache': Synset('cache.n.03'), 'Resource': Synset('resource.n.01'), 'Use': Synset('use.v.03'), 'Possessor': Synset('owner.n.02'), 'Descriptor': Synset('form.n.01')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {'cache.n': Synset('hoard.n.01'), 'stash.n': Synset('hoard.n.01')}\n",
      "_________________________________________\n",
      "=========================\n",
      "ANNOTAZIONI UMANE: \n",
      "FRAME ID:  153\n",
      "FRAME NAME:  Process_stopped_state\n",
      "\n",
      "FRAME SYNSET:  Synset('discontinue.v.01')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Process': Synset('process.n.06'), 'Time': Synset('time.n.01'), 'Duration': Synset('duration.n.03')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {}\n",
      "_________________________________________\n",
      "FRAME ID:  10\n",
      "FRAME NAME:  Transitive_action\n",
      "\n",
      "FRAME SYNSET:  Synset('action.n.01')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Agent': Synset('agent.n.02'), 'Patient': Synset('affected_role.n.01'), 'Event': Synset('event.n.01'), 'Depictive': Synset('delineative.s.01'), 'Result': Synset('consequence.n.01'), 'Means': Synset('means.n.02'), 'Manner': Synset('manner.n.01'), 'Time': Synset('time.n.01'), 'Place': Synset('place.n.02'), 'Cause': Synset('cause.n.01')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {}\n",
      "_________________________________________\n",
      "FRAME ID:  2411\n",
      "FRAME NAME:  Personal_success\n",
      "\n",
      "FRAME SYNSET:  Synset('success.n.02')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Person': Synset('person.n.01'), 'Time': Synset('time.n.02'), 'Degree': Synset('degree.n.02'), 'Endeavor': Synset('attempt.n.01'), 'Explanation': Synset('explanation.n.01'), 'Field': Synset('discipline.n.01')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {'success [person].n': Synset('achiever.n.01'), 'success [event].n': Synset('success.n.01'), 'success [state].n': Synset('success.n.03'), 'successful.a': Synset('successful.a.01'), 'arrive.v': Synset('arrive.v.02'), 'succeed.v': Synset('succeed.v.01')}\n",
      "_________________________________________\n",
      "FRAME ID:  1684\n",
      "FRAME NAME:  Scrutinizing_for\n",
      "\n",
      "FRAME SYNSET:  Synset('size_up.v.01')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Ground': Synset('ground.n.08'), 'Phenomenon': Synset('phenomenon.n.01'), 'Manner': Synset('manner.n.01'), 'Means': Synset('means.n.01'), 'Degree': Synset('degree.n.02'), 'Purpose': Synset('purpose.n.01'), 'Instrument': Synset('instrumental_role.n.01')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {}\n",
      "_________________________________________\n",
      "FRAME ID:  2576\n",
      "FRAME NAME:  Cache\n",
      "\n",
      "FRAME SYNSET:  Synset('hoard.n.01')\n",
      "\n",
      "FRAME ELEMENTS SYNSETS:  \n",
      " {'Cache': Synset('hoard.n.01'), 'Resource': Synset('resource.n.01'), 'Use': Synset('use.v.01'), 'Possessor': Synset('owner.n.02'), 'Descriptor': Synset('descriptor.n.02')}\n",
      "\n",
      "LEXICAL UNITS SYNSETS:  \n",
      " {'cache.n': Synset('hoard.n.01'), 'stash.n': Synset('hoard.n.01')}\n",
      "_________________________________________\n",
      "Accuratezza:  65.91 %\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    #Lista di oggetti di tipo ContextsFrame(vedere ContextsFrame)\n",
    "    contexts_frames_list = get_contexts_frames_list(getFrameSetForStudent(SURNAME))\n",
    "      \n",
    "    #Lista di oggetti di tipo SynsetsFrame (vedere Synsetsframe)\n",
    "    synsets_frames_list = get_synsets_frames_list(contexts_frames_list)\n",
    "    \n",
    "    print(\"=========================\")\n",
    "    print(\"RISULTATI SISTEMA: \")\n",
    "    for item in synsets_frames_list:\n",
    "        item.printSynsetsFrame()\n",
    "    \n",
    "    #Lista di oggetti di tipo SynsetsFrame (ma riguarda le annotazioni umane)\n",
    "    synsets_frames_list_annotations = get_synsets_frames_list_annotations()\n",
    "    \n",
    "    print(\"=========================\")\n",
    "    print(\"ANNOTAZIONI UMANE: \")\n",
    "    for item in synsets_frames_list_annotations:\n",
    "        item.printSynsetsFrame()\n",
    "    \n",
    "    #testing\n",
    "    total_accuracy(synsets_frames_list, synsets_frames_list_annotations)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39a781-938d-4437-abe9-efe844feedc2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7348500-07f3-480e-876b-d30a93b1baa8",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Attenzione: questo script è utile solo ai fini dello sviluppatore\n",
    "come aiuto alla annotazione\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#VALUTAZIONE FRAME NAME\n",
    "\n",
    "\n",
    "f = fn.frame(153)\n",
    "print(\"Process_stopped_state: \",f.definition)\n",
    "regex = \"stopped\"\n",
    "\n",
    "\n",
    "print(\"=================================================\")\n",
    "\n",
    "for synset in wn.synsets(regex):\n",
    "    print(\"\\n\", synset, synset.definition()\n",
    "    \n",
    "#VALUTAZIONE FRAME ELEMENTS\n",
    "\n",
    "\n",
    "print(\"=================================================\")\n",
    "\n",
    "frame_name = 'Duration'\n",
    "fed = f.FE[frame_name]\n",
    "print(\"Frame element definition: \",fed.definition)\n",
    "print(\"=================================================\")\n",
    "\n",
    "for synset in wn.synsets(frame_name):\n",
    "    print(\"\\n\", synset, synset.definition())\n",
    "\n",
    "\n",
    "#VALUTAZIONE LEXICAL UNITS\n",
    "\n",
    "\n",
    "print(\"=================================================\")\n",
    "\n",
    "lexical_unit_name = 'stash.n'\n",
    "lud = f.lexUnit[lexical_unit_name]\n",
    "print(\"Lexical unit definition: \",lud.definition)\n",
    "print(\"=================================================\")\n",
    "\n",
    "for synset in wn.synsets('stash'):\n",
    "    print(\"\\n\", synset, synset.definition())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca50b0-702a-424e-be7e-f87e3f2ebddc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
