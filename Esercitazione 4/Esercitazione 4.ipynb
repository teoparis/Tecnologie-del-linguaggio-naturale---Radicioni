{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe34c2c-0a02-4991-a579-f6fadf5955ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0797ee-e03f-462c-9f8b-eee35889babe",
   "metadata": {},
   "source": [
    "FUNZIONI UTILI PER L'ANALISI DEL TESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31130c55-85df-445c-81cb-af7cb83802cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotation_file(file):\n",
    "    res = []\n",
    "    with open(file, 'r', encoding=\"utf-8\") as fd:\n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            res.append(row)\n",
    "    return res\n",
    "\n",
    "# crea un dizionario, in cui ad ogni parola (chiave) corrisponde una lista\n",
    "# di babel synset presi del file \"SemEval17_IT_senses2sysensts.txt\"\n",
    "def get_senses_dictionary(word_list):\n",
    "    senses_for_words = dict()\n",
    "    file = open(\"SemEval17_IT_senses2synsets.txt\",\"r\",encoding=\"utf-8\")\n",
    "    lines = file.readlines()\n",
    "    for i in range(0,len(lines)):\n",
    "        line = lines[i]\n",
    "        line = line.replace(\"\\n\", \"\").replace(\"#\",\"\")\n",
    "        if line in word_list:\n",
    "            while True:\n",
    "                i += 1\n",
    "                babel_synset = lines[i].replace(\"\\n\", \"\")\n",
    "                if \"#\" in babel_synset: #vuol dire che non sto considerando più un babel synset\n",
    "                    break\n",
    "                if line not in senses_for_words:\n",
    "                    senses_for_words[line] = [babel_synset]\n",
    "                else:\n",
    "                    senses_for_words[line].append(babel_synset)\n",
    "    return senses_for_words\n",
    "\n",
    "# crea un dizionario delle annotazioni, in cui ad ogni coppia di parole\n",
    "# prese dal file delle annotazioni \"annotations1.tsv\" associa il valore\n",
    "# di similarità annotato da un essere umano\n",
    "def get_human_similarities_dictionary1():\n",
    "    human_similarities1 = dict()\n",
    "    annotations_file = open(\"annotations.tsv\", encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(annotations_file, delimiter=\"\\t\")\n",
    "    for row in read_tsv:\n",
    "        if row[0]: #verifico che non sia una riga vuota (può capitare)\n",
    "            human_similarities1[(row[0],row[1])] = row[2]\n",
    "    annotations_file.close()\n",
    "    return human_similarities1\n",
    "\n",
    "# crea un dizionario delle annotazioni, in cui ad ogni coppia di parole\n",
    "# prese dal file delle annotazioni \"annotations1.tsv\" associa il valore\n",
    "# di similarità annotato da un essere umano\n",
    "def get_human_similarities_dictionary():\n",
    "    human_similarities = dict()\n",
    "    annotations_file = open(\"annotations1.tsv\", encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(annotations_file, delimiter=\"\\t\")\n",
    "    for row in read_tsv:\n",
    "        if row[0]: #verifico che non sia una riga vuota (può capitare)\n",
    "            human_similarities[(row[0],row[1])] = row[2]\n",
    "    annotations_file.close()\n",
    "    return human_similarities\n",
    "\n",
    "# crea un dizionario delle annotazioni, in cui ad ogni coppia di parola\n",
    "# prese dal file delle annotazioni \"annotations2.tsv\" associa una coppia\n",
    "# di BABEL synset annotati da un essere umano sulla base delle annotazioni\n",
    "# di similarità del file \"annotations1.tsv\"\n",
    "def get_human_synsets_dictionary():\n",
    "    human_synsets = dict()\n",
    "    annotations_file = open(\"annotations2.tsv\", encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(annotations_file, delimiter=\"\\t\")\n",
    "    for row in read_tsv:\n",
    "        if row[0]: #verifico che non sia una riga vuota (può capitare)\n",
    "            human_synsets[((row[0],row[1]))] = (row[2],row[3])\n",
    "    annotations_file.close()\n",
    "    return human_synsets\n",
    "\n",
    "# restituisce tutte le parole presenti nella coppie valutate nel dizionario\n",
    "# delle annotazioni umane che viene dato in input\n",
    "def get_word_list(human_similarities_dictionary):\n",
    "    word_list = []\n",
    "    for pair in human_similarities_dictionary.keys():\n",
    "        word_list.append(pair[0])\n",
    "        word_list.append(pair[1])\n",
    "    return word_list\n",
    "\n",
    "# cerca un vettore NASARI per ogni babel synset in input\n",
    "# associati ad una parola. Resituisce un dizionario\n",
    "# che avrà come chiavi i babel synset e come valori\n",
    "# i vettori NASARI associati\n",
    "def get_NASARI_vectors(word_senses):\n",
    "    word_vectors = dict()\n",
    "    \n",
    "    NASARI_file = open(\"mini_NASARI.tsv\", encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(NASARI_file, delimiter=\"\\t\")\n",
    "\n",
    "    for row in read_tsv:\n",
    "        babel_synset = row[0].split(\"__\")[0]\n",
    "        if babel_synset in word_senses:\n",
    "            vector = [float(val) for val in row[1:]]\n",
    "            word_vectors[babel_synset] = vector\n",
    "\n",
    "    NASARI_file.close()\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96839d",
   "metadata": {},
   "source": [
    "FUNZIONI PER IL CALCOLO DELLA SIMILARITA' TRA DUE VETTORI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcola la similarità del coseno tra due vettori numerici\n",
    "# restituisce quindi il rapporto tra il prodotto scalare dei due vettori e il\n",
    "# prodotto della loro norma\n",
    "def c_similarity(vect1, vect2):\n",
    "    numerator = numpy.dot(vect1,vect2)\n",
    "    denominator = numpy.linalg.norm(vect1) * numpy.linalg.norm(vect2)\n",
    "    return numerator / denominator\n",
    "\n",
    "# massimizza la cosine_similarity tra due liste di vettori distribuzionali\n",
    "def max_cosine_similarity(word_vector1,word_vectors2):\n",
    "    max_cos_similarity = 0\n",
    "    synset_pair = ()\n",
    "    for babel_synset1 in word_vector1.keys():\n",
    "        for babel_synset2 in word_vectors2.keys():\n",
    "            cos_similarity = c_similarity(word_vector1[babel_synset1], word_vectors2[babel_synset2])\n",
    "            if cos_similarity > max_cos_similarity:\n",
    "                max_cos_similarity = cos_similarity\n",
    "                synset_pair = (babel_synset1,babel_synset2)\n",
    "    return max_cos_similarity, synset_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874055a0",
   "metadata": {},
   "source": [
    "SVILUPPO DEI DUE TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea una dizionario che associa ad ogni coppia di parole del dizionario\n",
    "# delle annotazioni umane delle similarità, un valore di similarità dato dalla massimizzazione della similarità\n",
    "# del coseno tra l'insieme dei vettori nasari associati ad una parola\n",
    "# e l'insieme dei vettori nasari associati all'altra parola\n",
    "# CONSEGNA 1\n",
    "def get_NASARI_similarities_dictionary(human_similarities_dictionary,senses_dictionary):\n",
    "    similarity_dictionary = dict()\n",
    "    for word_pair in human_similarities_dictionary:\n",
    "        \n",
    "        try:\n",
    "            word1_senses = senses_dictionary[word_pair[0]]\n",
    "            word2_senses = senses_dictionary[word_pair[1]]\n",
    "            \n",
    "            word1_vectors = get_NASARI_vectors(word1_senses)\n",
    "            word2_vectors = get_NASARI_vectors(word2_senses)\n",
    "        \n",
    "            similarity_value = max_cosine_similarity(word1_vectors,word2_vectors)[0]\n",
    "            similarity_dictionary[word_pair] = similarity_value\n",
    "        \n",
    "        except KeyError: #una delle due parole della coppia non c'è nel file \"SemEval17_IT_senses2synsets.txt\"\n",
    "            print(\"La coppia \", word_pair, \"non e' stata valutata\")\n",
    "            \n",
    "    return similarity_dictionary\n",
    "\n",
    "# crea un dizionario che associa ad ogni coppia di parole del dizionario\n",
    "# delle annotazioni umane dei sensi, una coppia di babel synset che massimizza la similarità\n",
    "# del coseno tra l'insieme dei vettori associati alla prima parola\n",
    "# e l'insieme dei vettori associati alla seconda parola\n",
    "# CONSEGNA 2\n",
    "def get_word_pair_synset_pair_dictionary(human_synsets_dictionary,senses_dictionary):\n",
    "    synsets_dictionary = dict()\n",
    "    for word_pair in human_synsets_dictionary:\n",
    "        try:\n",
    "            word1_senses = senses_dictionary[word_pair[0]]\n",
    "            word2_senses = senses_dictionary[word_pair[1]]\n",
    "            \n",
    "            word1_vectors = get_NASARI_vectors(word1_senses)\n",
    "            word2_vectors = get_NASARI_vectors(word2_senses)\n",
    "            \n",
    "            synset_pair = max_cosine_similarity(word1_vectors, word2_vectors)[1]\n",
    "            synsets_dictionary[word_pair] = synset_pair\n",
    "            \n",
    "        except KeyError: #una delle due parole della coppia non c'è nel file \"SemEval17_IT_senses2synsets.txt\"\n",
    "            print(\"La coppia \", word_pair, \"non e' stata valutata\")\n",
    "    return synsets_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf092fb1-31fd-4a65-8758-19695eacaec8",
   "metadata": {},
   "source": [
    "Mappa un cognome su uno dei 50 insiemi di coppie da annotare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a2c825-8321-4dab-a3fe-fd243b0d2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parisi         :\tcoppie nell'intervallo 451-500\n"
     ]
    }
   ],
   "source": [
    "def get_range(surname):\n",
    "    nof_elements = 500\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % 10)\n",
    "    idx_intervallo = base_idx * 50+1\n",
    "    return idx_intervallo \n",
    "\n",
    "input_name = \"Parisi\"\n",
    "\n",
    "values = []\n",
    "sx = get_range(input_name)\n",
    "values.append(sx)\n",
    "dx = sx+50-1\n",
    "intervallo = \"\" + str(sx) + \"-\" + str(dx)\n",
    "print('{:15}:\\tcoppie nell\\'intervallo {}'.format(input_name, intervallo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1772928-d8c9-46d1-af30-f431e9361d92",
   "metadata": {},
   "source": [
    "PROCESSO DELLA PRIMA ANNOTAZIONE MANUALE DELL'UTENTE\n",
    "\n",
    "Vengono esaminate le coppie di termini dal file \"it.test.data.txt\" in base al cognone (Parisi: coppie nell'intervallo 451-500) che vanno da INTERVAL_START a INTERVAL_END\n",
    "\n",
    "Il processo di annotazione è fatto in modo manuale dall'utente che assegna un punteggio di similarità da 0 a 4.\n",
    "\n",
    "0: Totally dissimilar and unrelated\n",
    "\n",
    "1: Dissimilar\n",
    "\n",
    "2: Slightly similar\n",
    "\n",
    "3: Similar\n",
    "\n",
    "4: Very similar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719bfaa-91d1-435b-9f28-d312dca33e9d",
   "metadata": {},
   "source": [
    "'''\n",
    "INTERVAL_START = 451\n",
    "INTERVAL_END = 500\n",
    "\n",
    "with open('annotations1.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "\n",
    "    with open(\"it.test.data.txt\", \"r\", encoding=\"utf8\") as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            if i >= INTERVAL_START - 1:\n",
    "                line = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "                print(\"==============================\")\n",
    "                word1, word2 = line[0], line[1]\n",
    "                print(word1, \" \", word2)\n",
    "                similarity_value = float(input(\"Inserire similarità (0-4): \"))\n",
    "                similarity_value = format(similarity_value, '.1f')\n",
    "                tsv_writer.writerow([word1, word2, similarity_value])\n",
    "                print(\"==============================\")\n",
    "            if i == INTERVAL_END - 1:\n",
    "                break\n",
    "    fp.close()\n",
    "    out_file.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba5896-484c-4cb7-9709-c14f74228bf3",
   "metadata": {},
   "source": [
    "PROCESSO DELLA SECONDA ANNOTAZIONE MANUALE DELL'UTENTE\n",
    "\n",
    "Anche in questo in caso vengono prese in considerazione le coppie di parole presenti nel file in base al cognome.\n",
    "\n",
    "Il processo di annotazione consiste nel predere la coppia di termini associarla alla coppia di bable synset ID e cosiderare, per entrambe i termini, i 3 sensi più simili presenti su WordNet, in questo ordine: Term1 Term2 BS1 BS2 Terms_in_BS1 Terms_in_BS2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05dc2f0-5311-4f5c-80c0-55aa5730d65b",
   "metadata": {},
   "source": [
    "\n",
    "with open('annotations2.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "\n",
    "    tsv_writer.writerow(['recessione', 'PIL', 'bn:00066516n','bn:00037570n','condizione macroeconomica,fattori produttivi,crescita economica','pil, P.I.L.,prodotto interno lordo'])\n",
    "    tsv_writer.writerow(['Cesare', 'Giulio Cesare', 'bn:00014550n','bn:00014550n','Gaio Giulio Cesare,Caio Giulio Cesare,imperatore','Gaio Giulio Cesare,Caio Giulio Cesare,imperatore'])\n",
    "    tsv_writer.writerow(['paziente', 'sessione', 'bn:00061017n','bn:00076588n',' ammalato,assistito,cliente ','fase,periodo,sessione'])\n",
    "    tsv_writer.writerow(['comportamentismo', 'terapia', 'bn:00009659n','bn:00076843n','behaviourismo,psicologia,comportamento  ','guarigione,malattie,metodi'])\n",
    "    tsv_writer.writerow(['imperatore', 'costituzione', 'bn:00014550n','bn:00059480n','Gaio Giulio Cesare,Caio Giulio Cesare,imperatore','organizzazione,formazione,organizzativo'])\n",
    "    tsv_writer.writerow(['matematico', 'spettacolo', 'bn:00053834n','bn:00067553n','persona,ricerche,sperimentazioni','rivista ,Teatro di rivista,spettacolo '])\n",
    "    tsv_writer.writerow(['entropia', 'informazione', 'bn:00031061n','bn:00046705n','casualita,azzardo,grandezza','Conoscenza,studio,dati '])\n",
    "    tsv_writer.writerow(['acqua di rose', 'olio di rosa', 'bn:00068288n','bn:00007010n','giulebbe,bevanda,estratto di rosa ','petali,rosa,estratto '])\n",
    "    tsv_writer.writerow(['agrume', 'pompelmo', 'bn:00019301n','bn:00019313n','frutti,piante,Rutaceae','Agrume,buccia gialla,amarognolo '])\n",
    "    tsv_writer.writerow(['Regina Vittoria', 'Inghilterra', 'bn:00065652n','bn:00013173n','regina,Regno Unito,Imperatrice ','Gran Bretagna,Regno Unito,Irlanda del Nord '])\n",
    "    tsv_writer.writerow(['Giochi Olimpici', 'spirito', 'bn:00058910n','bn:00040370n','olimpiade,Olimpiadi ,Manifestazione','fantasma,spettro,apparizione '])\n",
    "    tsv_writer.writerow(['vescovo', 'musulmano', 'bn:27267995n','bn:00055975n',' responsabile,chiese,cattolicesimo ','mussulmano,islamico,maomettano'])\n",
    "    tsv_writer.writerow(['uomo', 'sospetto', 'bn:00044576n','bn:00025884n','essere umano,Homo,umano ','convenuto,accusato ,imputato '])\n",
    "    tsv_writer.writerow(['meteorite', 'Terra', 'bn:00054602n','bn:00029424n','meteorite,Oggetto,spazio  ','mondo ,globo,terrestre '])\n",
    "    tsv_writer.writerow(['simbolo', 'segno', 'bn:00075652n','bn:00075652n','segno,significato convenzionale,elemento ','segno,significato convenzionale,elemento'])\n",
    "    tsv_writer.writerow(['antropologia', 'New York', 'bn:00004584n','bn:00041611n','Scienza,uomo,entita biologica ','Nuova York ,stato di New York,citta'])\n",
    "    tsv_writer.writerow(['tramonto', 'tavolo', 'bn:05692316n','bn:00075813n','crepuscolo,notte,illuminazione','tavola,mobilio,piano'])\n",
    "    tsv_writer.writerow(['cittadina', 'città', 'bn:00070724n','bn:00077773n','Insediamento umano,villaggio,borgo ','citta,cittadina ,paese '])\n",
    "    tsv_writer.writerow(['giacca', 'acqua minerale', 'bn:00047823n','bn:00055131n','cappotto,casacca,giacchetta ','minerale,bottiglia,acqua sorgiva '])\n",
    "    tsv_writer.writerow(['natura', 'flora', 'bn:00057017n','bn:00035324n','fenomeni,forze,cose','pianta,Plantae,vegetale '])\n",
    "    tsv_writer.writerow(['subroutine', 'compilatore','bn:00036826n','bn:00021344n','sottoprogramma,procedura,procedimento','Programma,linguaggio,istruzioni'])\n",
    "    tsv_writer.writerow(['Hamadan', 'Roma', 'bn:03266645n','bn:00015556n','citta,Iran,Ecbatana','Citta Eterna,Comune di Roma,impero romano '])\n",
    "    tsv_writer.writerow(['ombrello', 'stufa', 'bn:00078920n','bn:00074479n','parapioggia,paracqua,ombrellone','fornello,fuoco,apparecchio'])\n",
    "    tsv_writer.writerow(['onore', 'stima', 'bn:00027103n','bn:00031973n','dignità,decoro,onore','valutazione,estimazione,perizia'])\n",
    "    tsv_writer.writerow(['insegna', 'dignità', 'bn:00034960n','bn:00027103n','bandiera,segnalazioni,identificazione','decoro,onore,reputazione'])\n",
    "    tsv_writer.writerow(['schermo', 'monitor', 'bn:00027675n','bn:01132021n',' display,monitor,video','Monitor,schermo ,dispositivo'])\n",
    "    tsv_writer.writerow(['joystick', 'radar', 'bn:00022301n','bn:00054808n','cloche,barra,comando','radiolocalizzatore,posizione,rilevamento'])\n",
    "    tsv_writer.writerow(['basmati', 'riso jasmine', 'bn:00567353n','bn:02666084n','riso,grano,fragranza ','riso,chicco lungo,fiori'])\n",
    "    tsv_writer.writerow(['medaglia', 'scarpe da ginnastica', 'bn:23946490n','bn:00042319n','riconoscimento,Attestazione,distinzione','sneaker,takkies,attivita sportive'])\n",
    "    tsv_writer.writerow(['legge', 'piscina', 'bn:00048655n','bn:00056911n','diritto,giurisprudenza,legislazione','vasca,piscina coperta,nuotare'])\n",
    "    tsv_writer.writerow(['sorgente', 'scatola', 'bn:00036077n','bn:00012524n','fonte,polla,scaturigine','cassetta,astuccio,cassa'])\n",
    "    tsv_writer.writerow(['teatro', 'batteria', 'bn:00045002n','bn:00028891n','Edificio,opere,spettacolo ','tamburo,Membranofoni,membranofono '])\n",
    "    tsv_writer.writerow(['flora', 'web browser', 'bn:00035324n','bn:00013447n','pianta,Plantae,vegetale','browser,navigatore,informatica'])\n",
    "    tsv_writer.writerow(['camicia', 'cardigan', 'bn:00071142n','bn:00015958n','Indumento,cotone,maniche','golf,maglione,bottoni'])\n",
    "    tsv_writer.writerow(['poema', 'ritmo', 'bn:15205441n','bn:00009396n','poesia,versi,narrativo','tempo,pause,intervalli'])\n",
    "    tsv_writer.writerow(['profeta', 'prete', 'bn:00064759n','bn:00024459n','aedo,divinatore,vate','pastore,curato,Parroco'])\n",
    "    tsv_writer.writerow(['Oscar', 'stadio', 'bn:00000571n','bn:00005532n','Premio Oscar,Academy Award, cinema','arena,campo sportivo,palazzetto dello sport'])\n",
    "    tsv_writer.writerow(['backgammon', 'Go', 'bn:00007779n','bn:00040833n','tavola reale,sbaraglino,tric-trac','gioco da tavolo,giocatori ,Cina'])\n",
    "    tsv_writer.writerow(['farfalla', 'rosa', 'bn:00014271n','bn:00068283n','Insetto ,grandi ali ,Lepidotteri','rosaio,Fiore,pianta'])\n",
    "    tsv_writer.writerow(['recinto', 'salto', 'bn:00034048n','bn:00048558n','recinzione,barriera,cinta','movimento,salto,abilita'])\n",
    "    tsv_writer.writerow(['nichilismo', 'film', 'bn:00057710n','bn:00034471n','nihilismo,Dottrina filosofica ,societa ','spettacolo ,pellicola,opera cinematografica'])\n",
    "    tsv_writer.writerow(['asteroide', 'stella', 'bn:00006608n','bn:00073964n','planetoide,corpo celeste,pianeta terrestre','stella,sole,Corpo celeste'])\n",
    "    tsv_writer.writerow(['sommossa', 'disegno', 'bn:00047003n','bn:00028639n','ribellione,rivolta,insurrezione','figura,illustrazione ,riproduzione'])\n",
    "    tsv_writer.writerow(['intimo', 'corpo', 'bn:00079003n','bn:00011744n','biancheria intima,lingerie,indumento','organismo,tessuti,tessuti'])\n",
    "    tsv_writer.writerow(['Boeing', 'aereo', 'bn:01156257n','bn:00002275n','aereo militare,mezzo militare,spazioplano','aeromobile,velivolo,aeroplano'])\n",
    "    tsv_writer.writerow(['cameo', 'interpretazione', 'bn:02119437n','bn:00061560n','apparizione,personaggio famoso,spettacolo','performance,esecuzione,esibizione'])\n",
    "    tsv_writer.writerow(['mondo', 'Asia', 'bn:00029424n','bn:00006329n','terra,globo,globo terrestre','regione,supercontinente,continente'])\n",
    "    tsv_writer.writerow(['arancia', 'agrume', 'bn:17389700n','bn:00019301n','arancio ,albero,Rutaceae','Citrus,frutto,pianta'])\n",
    "    tsv_writer.writerow(['ghiacciaio', 'riscaldamento globale', 'bn:00040579n','bn:00040681n','ghiaccio,regioni montane,neve','clima,atmosfera,mutamento'])\n",
    "    tsv_writer.writerow(['galleria', 'percorso', 'bn:00078606n','bn:00067975n','tunnel,Passaggio,cunicolo','strada,via,Striscia di terreno'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d458e8-e56f-46d9-829d-4b0dc8d1cdd1",
   "metadata": {},
   "source": [
    "CONSEGNA 1: Consiste nell’annotare con punteggio di semantic similarity 50 coppie di termini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0345523-9f45-4c37-bce8-b12d33070db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALUTAZIONI DI SIMILARITA' UMANE: \n",
      "{('recessione', 'PIL'): '2.0', ('Cesare', 'Giulio Cesare'): '3.5', ('paziente', 'sessione'): '3.5', ('comportamentismo', 'terapia'): '1.0', ('imperatore', 'costituzione'): '1.5', ('matematico', 'spettacolo'): '0.0', ('entropia', 'informazione'): '2.0', ('acqua di rose', 'olio di rosa'): '2.0', ('agrume', 'pompelmo'): '3.0', ('Regina Vittoria', 'Inghilterra'): '3.5', ('Giochi Olimpici', 'spirito'): '1.5', ('vescovo', 'musulmano'): '3.0', ('uomo', 'sospetto'): '2.0', ('meteorite', 'Terra'): '2.5', ('simbolo', 'segno'): '4.0', ('antropologia', 'New York'): '0.5', ('tramonto', 'tavolo'): '0.0', ('cittadina', 'città'): '4.0', ('giacca', 'acqua minerale'): '0.0', ('natura', 'flora'): '3.5', ('subroutine', 'compilatore'): '3.0', ('Hamadan', 'Roma'): '2.0', ('ombrello', 'stufa'): '0.0', ('onore', 'stima'): '1.5', ('insegna', 'dignità'): '0.5', ('schermo', 'monitor'): '4.0', ('joystick', 'radar'): '1.5', ('basmati', 'riso jasmine'): '3.5', ('medaglia', 'scarpe da ginnastica'): '1.0', ('legge', 'piscina'): '0.0', ('sorgente', 'scatola'): '0.0', ('teatro', 'batteria'): '3.0', ('flora', 'web browser'): '0.0', ('camicia', 'cardigan'): '3.0', ('poema', 'ritmo'): '2.0', ('profeta', 'prete'): '2.0', ('Oscar', 'stadio'): '2.0', ('backgammon', 'Go'): '3.0', ('farfalla', 'rosa'): '1.0', ('recinto', 'salto'): '0.5', ('nichilismo', 'film'): '0.5', ('asteroide', 'stella'): '3.0', ('sommossa', 'disegno'): '0.0', ('intimo', 'corpo'): '2.5', ('Boeing', 'aereo'): '3.5', ('cameo', 'interpretazione'): '2.5', ('mondo', 'Asia'): '3.0', ('arancia', 'agrume'): '3.5', ('ghiacciaio', 'riscaldamento globale'): '1.5', ('galleria', 'percorso'): '2.0'}\n",
      "\n",
      "VALUTAZIONI DI SIMILARITA' DEL SISTEMA: \n",
      "{('recessione', 'PIL'): 0.8985258184822787, ('Cesare', 'Giulio Cesare'): 0.9999999999999999, ('paziente', 'sessione'): 0.48149233356108495, ('comportamentismo', 'terapia'): 0.629044171856524, ('imperatore', 'costituzione'): 0.6355656042750495, ('matematico', 'spettacolo'): 0.554121181810472, ('entropia', 'informazione'): 0.7056054648248632, ('acqua di rose', 'olio di rosa'): 0.7633867912855887, ('agrume', 'pompelmo'): 0.9789173082506498, ('Regina Vittoria', 'Inghilterra'): 0.6251481013724084, ('Giochi Olimpici', 'spirito'): 0.5918394837423236, ('vescovo', 'musulmano'): 0.6108448887039739, ('uomo', 'sospetto'): 0.9999999999999999, ('meteorite', 'Terra'): 0.8834348407866606, ('simbolo', 'segno'): 1.0000000000000002, ('antropologia', 'New York'): 0.7615881696780595, ('tramonto', 'tavolo'): 0.42469578746890363, ('cittadina', 'città'): 1.0000000000000002, ('giacca', 'acqua minerale'): 0.42174602648632686, ('natura', 'flora'): 0.7387780406833512, ('subroutine', 'compilatore'): 0.83144212314946, ('Hamadan', 'Roma'): 0.5940460190553193, ('ombrello', 'stufa'): 0.46734995843951077, ('onore', 'stima'): 0.7689449017614528, ('insegna', 'dignità'): 0.5985250966022299, ('schermo', 'monitor'): 1.0, ('joystick', 'radar'): 0.5894986010358945, ('basmati', 'riso jasmine'): 0.9401064443037185, ('medaglia', 'scarpe da ginnastica'): 0.37253882186513154, ('legge', 'piscina'): 0.4367673817917988, ('sorgente', 'scatola'): 0.5267729122025209, ('teatro', 'batteria'): 0.7843951357255209, ('flora', 'web browser'): 0.5305495684664866, ('camicia', 'cardigan'): 0.965220712232885, ('poema', 'ritmo'): 0.7874981624885306, ('profeta', 'prete'): 0.7333253701159547, ('Oscar', 'stadio'): 0.626483953535518, ('backgammon', 'Go'): 0.9394803704507002, ('farfalla', 'rosa'): 0.6634009700030588, ('recinto', 'salto'): 0.6505464444799082, ('nichilismo', 'film'): 0.5835485078133711, ('asteroide', 'stella'): 0.8216879801335856, ('sommossa', 'disegno'): 0.44048376584606336, ('intimo', 'corpo'): 0.43128846183517205, ('Boeing', 'aereo'): 0.8985004700455775, ('cameo', 'interpretazione'): 0.619234539638481, ('mondo', 'Asia'): 0.6629075158915035, ('arancia', 'agrume'): 0.9789173082506498, ('ghiacciaio', 'riscaldamento globale'): 0.5118958330631778, ('galleria', 'percorso'): 0.7722676195145126}\n",
      "\n",
      "Pearson Correlation:  [[1.         0.70174527]\n",
      " [0.70174527 1.        ]]\n",
      "\n",
      "Spearman Correlation:  SpearmanrResult(correlation=0.7032851886460076, pvalue=1.2316469446995335e-08)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    human_similarities_dictionary = get_human_similarities_dictionary()\n",
    "    senses_dictionary = get_senses_dictionary(get_word_list(human_similarities_dictionary))\n",
    "    NASARI_similarities_dictionary = get_NASARI_similarities_dictionary(human_similarities_dictionary, senses_dictionary)\n",
    "    human_similarities = []\n",
    "    NASARI_similarities = []\n",
    "    for word_pair in human_similarities_dictionary.keys():\n",
    "        if word_pair in NASARI_similarities_dictionary.keys():\n",
    "            human_similarities.append(float(human_similarities_dictionary[word_pair]))\n",
    "            NASARI_similarities.append(NASARI_similarities_dictionary[word_pair])\n",
    "    \n",
    "    print()\n",
    "    print(\"VALUTAZIONI DI SIMILARITA' UMANE: \")\n",
    "    print(human_similarities_dictionary)\n",
    "    print()\n",
    "    print(\"VALUTAZIONI DI SIMILARITA' DEL SISTEMA: \")\n",
    "    print(NASARI_similarities_dictionary)\n",
    "    print()\n",
    "    print(\"Pearson Correlation: \",np.corrcoef(human_similarities, NASARI_similarities))\n",
    "    print()\n",
    "    print(\"Spearman Correlation: \",sp.stats.spearmanr(human_similarities, NASARI_similarities))\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6acaba0-3ca5-4b9a-b405-f8f10391425f",
   "metadata": {},
   "source": [
    "CONSEGNA 2: Consiste nell’individuare i sensi selezionati nel giudizio di similarità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb78449-3aae-434a-ae25-8dcc3673a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSEGNAMENTI SYNSETS UMANI: \n",
      "{('recessione', 'PIL'): ('bn:00066516n', 'bn:00037570n'), ('Cesare', 'Giulio Cesare'): ('bn:00014550n', 'bn:00014550n'), ('paziente', 'sessione'): ('bn:00061017n', 'bn:00076588n'), ('comportamentismo', 'terapia'): ('bn:00009659n', 'bn:00076843n'), ('imperatore', 'costituzione'): ('bn:00014550n', 'bn:00059480n'), ('matematico', 'spettacolo'): ('bn:00053834n', 'bn:00067553n'), ('entropia', 'informazione'): ('bn:00031061n', 'bn:00046705n'), ('acqua di rose', 'olio di rosa'): ('bn:00068288n', 'bn:00007010n'), ('agrume', 'pompelmo'): ('bn:00019301n', 'bn:00019313n'), ('Regina Vittoria', 'Inghilterra'): ('bn:00065652n', 'bn:00013173n'), ('Giochi Olimpici', 'spirito'): ('bn:00058910n', 'bn:00040370n'), ('vescovo', 'musulmano'): ('bn:27267995n', 'bn:00055975n'), ('uomo', 'sospetto'): ('bn:00044576n', 'bn:00025884n'), ('meteorite', 'Terra'): ('bn:00054602n', 'bn:00029424n'), ('simbolo', 'segno'): ('bn:00075652n', 'bn:00075652n'), ('antropologia', 'New York'): ('bn:00004584n', 'bn:00041611n'), ('tramonto', 'tavolo'): ('bn:05692316n', 'bn:00075813n'), ('cittadina', 'città'): ('bn:00070724n', 'bn:00077773n'), ('giacca', 'acqua minerale'): ('bn:00047823n', 'bn:00055131n'), ('natura', 'flora'): ('bn:00057017n', 'bn:00035324n'), ('subroutine', 'compilatore'): ('bn:00036826n', 'bn:00021344n'), ('Hamadan', 'Roma'): ('bn:03266645n', 'bn:00015556n'), ('ombrello', 'stufa'): ('bn:00078920n', 'bn:00074479n'), ('onore', 'stima'): ('bn:00027103n', 'bn:00031973n'), ('insegna', 'dignità'): ('bn:00034960n', 'bn:00027103n'), ('schermo', 'monitor'): ('bn:00027675n', 'bn:01132021n'), ('joystick', 'radar'): ('bn:00022301n', 'bn:00054808n'), ('basmati', 'riso jasmine'): ('bn:00567353n', 'bn:02666084n'), ('medaglia', 'scarpe da ginnastica'): ('bn:23946490n', 'bn:00042319n'), ('legge', 'piscina'): ('bn:00048655n', 'bn:00056911n'), ('sorgente', 'scatola'): ('bn:00036077n', 'bn:00012524n'), ('teatro', 'batteria'): ('bn:00045002n', 'bn:00028891n'), ('flora', 'web browser'): ('bn:00035324n', 'bn:00013447n'), ('camicia', 'cardigan'): ('bn:00071142n', 'bn:00015958n'), ('poema', 'ritmo'): ('bn:15205441n', 'bn:00009396n'), ('profeta', 'prete'): ('bn:00064759n', 'bn:00024459n'), ('Oscar', 'stadio'): ('bn:00000571n', 'bn:00005532n'), ('backgammon', 'Go'): ('bn:00007779n', 'bn:00040833n'), ('farfalla', 'rosa'): ('bn:00014271n', 'bn:00068283n'), ('recinto', 'salto'): ('bn:00034048n', 'bn:00048558n'), ('nichilismo', 'film'): ('bn:00057710n', 'bn:00034471n'), ('asteroide', 'stella'): ('bn:00006608n', 'bn:00073964n'), ('sommossa', 'disegno'): ('bn:00047003n', 'bn:00028639n'), ('intimo', 'corpo'): ('bn:00079003n', 'bn:00011744n'), ('Boeing', 'aereo'): ('bn:01156257n', 'bn:00002275n'), ('cameo', 'interpretazione'): ('bn:02119437n', 'bn:00061560n'), ('mondo', 'Asia'): ('bn:00029424n', 'bn:00006329n'), ('arancia', 'agrume'): ('bn:17389700n', 'bn:00019301n'), ('ghiacciaio', 'riscaldamento globale'): ('bn:00040579n', 'bn:00040681n'), ('galleria', 'percorso'): ('bn:00078606n', 'bn:00067975n')}\n",
      "\n",
      "'ASSEGNAMENTI SYNSETS DEL SISTEMA: \n",
      "{('recessione', 'PIL'): ('bn:00066516n', 'bn:00037570n'), ('Cesare', 'Giulio Cesare'): ('bn:00014550n', 'bn:00014550n'), ('paziente', 'sessione'): ('bn:00001742n', 'bn:03751534n'), ('comportamentismo', 'terapia'): ('bn:00009659n', 'bn:00076843n'), ('imperatore', 'costituzione'): ('bn:00014550n', 'bn:02436267n'), ('matematico', 'spettacolo'): ('bn:00053834n', 'bn:00305552n'), ('entropia', 'informazione'): ('bn:17267027n', 'bn:00046705n'), ('acqua di rose', 'olio di rosa'): ('bn:00068288n', 'bn:00007010n'), ('agrume', 'pompelmo'): ('bn:00019301n', 'bn:00041408n'), ('Regina Vittoria', 'Inghilterra'): ('bn:00065652n', 'bn:00030861n'), ('Giochi Olimpici', 'spirito'): ('bn:00058913n', 'bn:00044468n'), ('vescovo', 'musulmano'): ('bn:03012712n', 'bn:00047600n'), ('uomo', 'sospetto'): ('bn:00053097n', 'bn:00075447n'), ('meteorite', 'Terra'): ('bn:00054598n', 'bn:00029424n'), ('simbolo', 'segno'): ('bn:00075652n', 'bn:00075652n'), ('antropologia', 'New York'): ('bn:02529040n', 'bn:02530635n'), ('tramonto', 'tavolo'): ('bn:01888833n', 'bn:00075813n'), ('cittadina', 'città'): ('bn:00077773n', 'bn:00077773n'), ('giacca', 'acqua minerale'): ('bn:00041211n', 'bn:00055131n'), ('natura', 'flora'): ('bn:00081220n', 'bn:00012321n'), ('subroutine', 'compilatore'): ('bn:00036826n', 'bn:00021344n'), ('Hamadan', 'Roma'): ('bn:03266645n', 'bn:00660953n'), ('ombrello', 'stufa'): ('bn:00078920n', 'bn:00074479n'), ('onore', 'stima'): ('bn:00044654n', 'bn:00031654n'), ('insegna', 'dignità'): ('bn:00002823n', 'bn:00025772n'), ('schermo', 'monitor'): ('bn:00027675n', 'bn:00027675n'), ('joystick', 'radar'): ('bn:00022301n', 'bn:00054808n'), ('basmati', 'riso jasmine'): ('bn:00567353n', 'bn:02666084n'), ('medaglia', 'scarpe da ginnastica'): ('bn:00054078n', 'bn:00068586n'), ('legge', 'piscina'): ('bn:00064426n', 'bn:02332519n'), ('sorgente', 'scatola'): ('bn:00036077n', 'bn:00015103n'), ('teatro', 'batteria'): ('bn:00034270n', 'bn:00021287n'), ('flora', 'web browser'): ('bn:03260352n', 'bn:00013447n'), ('camicia', 'cardigan'): ('bn:00028687n', 'bn:00015958n'), ('poema', 'ritmo'): ('bn:00063193n', 'bn:00063201n'), ('profeta', 'prete'): ('bn:00064759n', 'bn:00057892n'), ('Oscar', 'stadio'): ('bn:00407538n', 'bn:00061898n'), ('backgammon', 'Go'): ('bn:00007779n', 'bn:00040833n'), ('farfalla', 'rosa'): ('bn:00012473n', 'bn:00062507n'), ('recinto', 'salto'): ('bn:00060140n', 'bn:00048558n'), ('nichilismo', 'film'): ('bn:00057710n', 'bn:00735555n'), ('asteroide', 'stella'): ('bn:00055203n', 'bn:00073965n'), ('sommossa', 'disegno'): ('bn:01480882n', 'bn:00028562n'), ('intimo', 'corpo'): ('bn:00021740n', 'bn:03119994n'), ('Boeing', 'aereo'): ('bn:01156257n', 'bn:00001697n'), ('cameo', 'interpretazione'): ('bn:03871797n', 'bn:00061560n'), ('mondo', 'Asia'): ('bn:00045153n', 'bn:03667810n'), ('arancia', 'agrume'): ('bn:00059249n', 'bn:00019301n'), ('ghiacciaio', 'riscaldamento globale'): ('bn:00040579n', 'bn:00040681n'), ('galleria', 'percorso'): ('bn:14530939n', 'bn:00061006n')}\n",
      "\n",
      "Accuratezza sui singoli elementi:  0.42\n",
      "Accuratezza sulle coppie:  0.22\n",
      "Cohen's Kappa score:  0.6863565081024569\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    human_similarities_dictionary = get_human_similarities_dictionary()\n",
    "    senses_dictionary = get_senses_dictionary(get_word_list(human_similarities_dictionary))\n",
    "    human_synsets_dictionary = get_human_synsets_dictionary()\n",
    "    word_pair_synset_pair_dictionary = get_word_pair_synset_pair_dictionary(human_synsets_dictionary, senses_dictionary)\n",
    "    human_similarities = []\n",
    "    human_similarities1 = []\n",
    "    word1 = []\n",
    "    word2 = []\n",
    "    annotation1 = read_annotation_file(\"annotations1.tsv\")\n",
    "    annotation2 = read_annotation_file(\"annotations.tsv\")\n",
    "\n",
    "    print()\n",
    "    print(\"ASSEGNAMENTI SYNSETS UMANI: \")\n",
    "    print(human_synsets_dictionary)\n",
    "    print()\n",
    "    print(\"'ASSEGNAMENTI SYNSETS DEL SISTEMA: \")\n",
    "    print(word_pair_synset_pair_dictionary)\n",
    "    print()\n",
    "    \n",
    "    #calcolo accuratezza sui singoli elementi\n",
    "    checked = 0\n",
    "    for word_pair in human_synsets_dictionary.keys():\n",
    "        synset_pair = word_pair_synset_pair_dictionary[word_pair]\n",
    "        human_synsets_pair = human_synsets_dictionary[word_pair]\n",
    "        if synset_pair[0] == human_synsets_pair[0]:\n",
    "            checked += 1\n",
    "        if synset_pair[1] == human_synsets_pair[1]:\n",
    "            checked += 1\n",
    "    evaluated = len(human_synsets_dictionary.keys()) * 2\n",
    "    print(\"Accuratezza sui singoli elementi: \", checked / evaluated)\n",
    "    \n",
    "    #calcolo accuratezza sulle coppie\n",
    "    checked = 0\n",
    "    for word_pair in human_synsets_dictionary.keys():\n",
    "        synset_pair = word_pair_synset_pair_dictionary[word_pair]\n",
    "        human_synsets_pair = human_synsets_dictionary[word_pair]\n",
    "        if (synset_pair[0] == human_synsets_pair[0]) and (synset_pair[1] == human_synsets_pair[1]):\n",
    "            checked += 1\n",
    "    evaluated = len(human_synsets_dictionary.keys())\n",
    "    print(\"Accuratezza sulle coppie: \", checked / evaluated)\n",
    "\n",
    "    for el in annotation1:\n",
    "        word1.append(el[0].lower())\n",
    "        word2.append(el[1].lower())\n",
    "        human_similarities.append(float(el[2]))\n",
    "    for el in annotation2:\n",
    "        human_similarities1.append(float(el[2]))\n",
    "\n",
    "    int_annotation1_score = [int(i) for i in human_similarities]\n",
    "    int_annotation2_score = [int(i) for i in human_similarities1]\n",
    "\n",
    "    cohen_score = cohen_kappa_score(int_annotation1_score, int_annotation2_score)\n",
    "    print(\"Cohen's Kappa score: \", cohen_score)\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
