{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "\n",
    "#crea un dizionario, in cui ad ogni parola (chiave) corrisponde una lista\n",
    "#di babel synset presi del file \"SemEval17_IT_senses2sysensts.txt\"\n",
    "#es. un estratto: \n",
    "\"\"\"{.....'cifra': ['bn:00019153n', 'bn:00025702n', 'bn:00055715n', 'bn:01412291n', \n",
    "'bn:00034392n', 'bn:00024979n', 'bn:00058287n', 'bn:00034394n', 'bn:00003601n', \n",
    "'bn:00019155n'], \n",
    "   'dollaro': ['bn:00010038n', 'bn:00007240n', 'bn:00028115n', \n",
    " 'bn:00028114n', 'bn:00044648n', 'bn:00071729n', 'bn:00050950n', \n",
    " 'bn:00013472n', 'bn:00016907n', 'bn:15584900n', 'bn:00042310n', \n",
    " 'bn:00034409n', 'bn:00079129n', 'bn:00047909n', 'bn:00057522n', \n",
    " 'bn:00007961n', 'bn:00078306n', 'bn:00082043n', 'bn:00075926n', \n",
    " 'bn:00008503n', 'bn:00009726n', 'bn:14987182n', 'bn:00013578n', \n",
    " 'bn:00015129n'].....}\"\"\"\n",
    "def get_senses_dictionary(word_list):\n",
    "    senses_for_words = dict()\n",
    "    file = open(\"SemEval17_IT_senses2synsets.txt\",\"r\",encoding=\"utf8\")\n",
    "    lines = file.readlines()\n",
    "    for i in range(0,len(lines)):\n",
    "        line = lines[i]\n",
    "        line = line.replace(\"\\n\", \"\").replace(\"#\",\"\")\n",
    "        if line in word_list:\n",
    "            while True:\n",
    "                i += 1\n",
    "                babel_synset = lines[i].replace(\"\\n\", \"\")\n",
    "                if \"#\" in babel_synset: #vuol dire che non sto considerando più un babel synset\n",
    "                    break\n",
    "                if line not in senses_for_words:\n",
    "                    senses_for_words[line] = [babel_synset]\n",
    "                else:\n",
    "                    senses_for_words[line].append(babel_synset)\n",
    "    return senses_for_words\n",
    "                \n",
    "                \n",
    "#crea un dizionario delle annotazioni, in cui ad ogni coppia di parole\n",
    "#prese dal file delle annotazioni \"annotations1.tsv\" associa il valore\n",
    "#di similarità annotato da un essere umano\n",
    "\"\"\"es: un estratto {('terremoto', 'scossa'): '3.4', ('patrimonio', 'azione'): \n",
    "                 '0.3', ('ebreo', 'Gerusalemme'): '2.0', \n",
    "                 ('nuvolosità', 'previsione'): '1.2', \n",
    "                 ('dizionario', 'enciclopedia'): '3.1'....}\"\"\"       \n",
    "def get_human_similarities_dictionary():\n",
    "    human_similarities = dict()\n",
    "    annotations_file = open(\"annotations1.tsv\", encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(annotations_file, delimiter=\"\\t\")\n",
    "    for row in read_tsv:\n",
    "        if row[0]: #verifico che non sia una riga vuota (può capitare)\n",
    "            human_similarities[(row[0],row[1])] = row[2]\n",
    "    annotations_file.close()\n",
    "    return human_similarities\n",
    "\n",
    "#crea un dizionario delle annotazioni, in cui ad ogni coppia di parola\n",
    "#prese dal file delle annotazioni \"annotations2.tsv\" associa una coppia\n",
    "#di BABEL synset annotati da un essere umano sulla base delle annotazioni\n",
    "#di similarità del file \"annotations1.tsv\"\n",
    "\"\"\"es: un estratto {('terremoto', 'scossa'): ('bn:00029448n', 'bn:00029441n'), \n",
    "            ('patrimonio', 'azione'): ('bn:00080746n', 'bn:00070912n'), \n",
    "            ('ebreo', 'Gerusalemme'): ('bn:00043492n', 'bn:00015555n'),...}\"\"\"\n",
    "def get_human_synsets_dictionary():\n",
    "    human_synsets = dict()\n",
    "    annotations_file = open(\"annotations2.tsv\", encoding=\"utf-8\")\n",
    "    read_tsv = csv.reader(annotations_file, delimiter=\"\\t\")\n",
    "    for row in read_tsv:\n",
    "        if row[0]: #verifico che non sia una riga vuota (può capitare)\n",
    "            human_synsets[((row[0],row[1]))] = (row[2],row[3])\n",
    "    annotations_file.close()\n",
    "    return human_synsets\n",
    "\n",
    "\n",
    "#restituisce tutte le parole presenti nella coppie valutate nel dizionario\n",
    "#delle annotazioni umane che viene dato in input        \n",
    "def get_word_list(human_similarities_dictionary):\n",
    "    word_list = []\n",
    "    for pair in human_similarities_dictionary.keys():\n",
    "        word_list.append(pair[0])\n",
    "        word_list.append(pair[1])\n",
    "    return word_list\n",
    "\n",
    "#crea una dizionario che associa ad ogni coppia di parole del dizionario\n",
    "#delle annotazioni umane delle similarità, un valore di similarità dato dalla massimizzazione della similarità\n",
    "#del coseno tra l'insieme dei vettori nasari associati ad una parola\n",
    "#e l'insieme dei vettori nasari associati all'altra parola\n",
    "#CONSEGNA 1\n",
    "def get_NASARI_similarities_dictionary(human_similarities_dictionary,senses_dictionary):\n",
    "    similarity_dictionary = dict()\n",
    "    for word_pair in human_similarities_dictionary:\n",
    "        \n",
    "        try:\n",
    "            word1_senses = senses_dictionary[word_pair[0]]\n",
    "            word2_senses = senses_dictionary[word_pair[1]]\n",
    "              \n",
    "            word1_vectors = get_NASARI_vectors(word1_senses)\n",
    "            word2_vectors = get_NASARI_vectors(word2_senses)\n",
    "        \n",
    "            similarity_value = max_cosine_similarity(word1_vectors,word2_vectors)[0]\n",
    "        \n",
    "            similarity_dictionary[word_pair] = similarity_value\n",
    "        \n",
    "        except KeyError: #una delle due parole della coppia non c'è nel file \"SemEval17_IT_senses2synsets.txt\"\n",
    "            print(\"La coppia \", word_pair, \"non e' stata valutata\")\n",
    "            \n",
    "    return similarity_dictionary\n",
    "\n",
    "#crea un dizionario che associa ad ogni coppia di parole del dizionario\n",
    "#delle annotazioni umane dei sensi, una coppia di babel synset che massimizza la similarità\n",
    "#del coseno tra l'insieme dei vettori associati alla prima parola\n",
    "#e l'insieme dei vettori associati alla seconda parola\n",
    "#CONSEGNA 2\n",
    "def get_word_pair_synset_pair_dictionary(human_synsets_dictionary,senses_dictionary):\n",
    "    synsets_dictionary = dict()\n",
    "    for word_pair in human_synsets_dictionary:\n",
    "        try:\n",
    "            word1_senses = senses_dictionary[word_pair[0]]\n",
    "            word2_senses = senses_dictionary[word_pair[1]]\n",
    "              \n",
    "            word1_vectors = get_NASARI_vectors(word1_senses)\n",
    "            word2_vectors = get_NASARI_vectors(word2_senses)\n",
    "            \n",
    "            #TO-DO\n",
    "            synset_pair = max_cosine_similarity(word1_vectors, word2_vectors)[1]\n",
    "            \n",
    "            synsets_dictionary[word_pair] = synset_pair\n",
    "            \n",
    "        except KeyError: #una delle due parole della coppia non c'è nel file \"SemEval17_IT_senses2synsets.txt\"\n",
    "            print(\"La coppia \", word_pair, \"non e' stata valutata\")\n",
    "    return synsets_dictionary\n",
    "            \n",
    "\n",
    "#cerca un vettore NASARI per ogni babel synset in input\n",
    "#associati ad una parola. Resituisce un dizionario\n",
    "#che avrà come chiavi i babel synset e come valori\n",
    "#i vettori NASARI associati\n",
    "def get_NASARI_vectors(word_senses):\n",
    "   word_vectors = dict()\n",
    "    \n",
    "   NASARI_file = open(\"mini_NASARI.tsv\", encoding=\"utf-8\")\n",
    "   read_tsv = csv.reader(NASARI_file, delimiter=\"\\t\")\n",
    "   \n",
    "   for row in read_tsv:\n",
    "       babel_synset = row[0].split(\"__\")[0]\n",
    "       if babel_synset in word_senses:\n",
    "           vector = [float(val) for val in row[1:]]\n",
    "           word_vectors[babel_synset] = vector\n",
    "   \n",
    "   NASARI_file.close()\n",
    "   return word_vectors       \n",
    "\n",
    "#massimizza la cosine_similarity tra due liste di vettori distribuzionali\n",
    "def max_cosine_similarity(word_vector1,word_vectors2):\n",
    "    max_cos_similarity = 0\n",
    "    synset_pair = None\n",
    "    for babel_synset1 in word_vector1.keys():\n",
    "        for babel_synset2 in word_vectors2.keys():\n",
    "            cos_similarity = c_similarity(word_vector1[babel_synset1], word_vectors2[babel_synset2])\n",
    "            if cos_similarity > max_cos_similarity:\n",
    "                max_cos_similarity = cos_similarity\n",
    "                synset_pair = (babel_synset1,babel_synset2)\n",
    "    return max_cos_similarity, synset_pair \n",
    "\n",
    "#calcola la similarità del coseno tra due vettori numerici\n",
    "#restituisce quindi il rapporto tra il prodotto scalare die due vettori e il\n",
    "#prodotto della loro norma        \n",
    "def c_similarity(vect1, vect2):\n",
    "    numerator = numpy.dot(vect1,vect2)\n",
    "    denominator = numpy.linalg.norm(vect1) * numpy.linalg.norm(vect2)\n",
    "    return numerator / denominator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALUTAZIONI DI SIMILARITA' UMANE: \n",
      "{('recessione', 'PIL'): '2.0', ('Cesare', 'Giulio Cesare'): '3.5', ('paziente', 'sessione'): '3.5', ('comportamentismo', 'terapia'): '1.0', ('imperatore', 'costituzione'): '1.5', ('matematico', 'spettacolo'): '0.0', ('entropia', 'informazione'): '2.0', ('acqua di rose', 'olio di rosa'): '2.0', ('agrume', 'pompelmo'): '3.0', ('Regina Vittoria', 'Inghilterra'): '3.5', ('Giochi Olimpici', 'spirito'): '1.5', ('vescovo', 'musulmano'): '3.0', ('uomo', 'sospetto'): '2.0', ('meteorite', 'Terra'): '2.5', ('simbolo', 'segno'): '4.0', ('antropologia', 'New York'): '0.5', ('tramonto', 'tavolo'): '0.0', ('cittadina', 'città'): '4.0', ('giacca', 'acqua minerale'): '0.0', ('natura', 'flora'): '3.5', ('subroutine', 'compilatore'): '3.0', ('Hamadan', 'Roma'): '2.0', ('ombrello', 'stufa'): '0.0', ('onore', 'stima'): '1.5', ('insegna', 'dignità'): '0.5', ('schermo', 'monitor'): '4.0', ('joystick', 'radar'): '1.5', ('basmati', 'riso jasmine'): '3.5', ('medaglia', 'scarpe da ginnastica'): '1.0', ('legge', 'piscina'): '0.0', ('sorgente', 'scatola'): '0.0', ('teatro', 'batteria'): '3.0', ('flora', 'web browser'): '0.0', ('camicia', 'cardigan'): '3.0', ('poema', 'ritmo'): '2.0', ('profeta', 'prete'): '2.0', ('Oscar', 'stadio'): '2.0', ('backgammon', 'Go'): '3.0', ('farfalla', 'rosa'): '1.0', ('recinto', 'salto'): '0.5', ('nichilismo', 'film'): '0.5', ('asteroide', 'stella'): '3.0', ('sommossa', 'disegno'): '0.0', ('intimo', 'corpo'): '2.5', ('Boeing', 'aereo'): '3.5', ('cameo', 'interpretazione'): '2.5', ('semestre', 'quadrimestre'): '3.0', ('arancia', 'agrume'): '3.5', ('ghiacciaio', 'riscaldamento globale'): '1.5', ('galleria', 'percorso'): '2.0'}\n",
      "\n",
      "VALUTAZIONI DI SIMILARITA' DEL SISTEMA: \n",
      "{('recessione', 'PIL'): 0.8985258184822787, ('Cesare', 'Giulio Cesare'): 0.9999999999999999, ('paziente', 'sessione'): 0.48149233356108495, ('comportamentismo', 'terapia'): 0.629044171856524, ('imperatore', 'costituzione'): 0.6355656042750495, ('matematico', 'spettacolo'): 0.554121181810472, ('entropia', 'informazione'): 0.7056054648248632, ('acqua di rose', 'olio di rosa'): 0.7633867912855887, ('agrume', 'pompelmo'): 0.9789173082506498, ('Regina Vittoria', 'Inghilterra'): 0.6251481013724084, ('Giochi Olimpici', 'spirito'): 0.5918394837423236, ('vescovo', 'musulmano'): 0.6108448887039739, ('uomo', 'sospetto'): 0.9999999999999999, ('meteorite', 'Terra'): 0.8834348407866606, ('simbolo', 'segno'): 1.0000000000000002, ('antropologia', 'New York'): 0.7615881696780595, ('tramonto', 'tavolo'): 0.42469578746890363, ('cittadina', 'città'): 1.0000000000000002, ('giacca', 'acqua minerale'): 0.42174602648632686, ('natura', 'flora'): 0.7387780406833512, ('subroutine', 'compilatore'): 0.83144212314946, ('Hamadan', 'Roma'): 0.5940460190553193, ('ombrello', 'stufa'): 0.46734995843951077, ('onore', 'stima'): 0.7689449017614528, ('insegna', 'dignità'): 0.5985250966022299, ('schermo', 'monitor'): 1.0, ('joystick', 'radar'): 0.5894986010358945, ('basmati', 'riso jasmine'): 0.9401064443037185, ('medaglia', 'scarpe da ginnastica'): 0.37253882186513154, ('legge', 'piscina'): 0.4367673817917988, ('sorgente', 'scatola'): 0.5267729122025209, ('teatro', 'batteria'): 0.7843951357255209, ('flora', 'web browser'): 0.5305495684664866, ('camicia', 'cardigan'): 0.965220712232885, ('poema', 'ritmo'): 0.7874981624885306, ('profeta', 'prete'): 0.7333253701159547, ('Oscar', 'stadio'): 0.626483953535518, ('backgammon', 'Go'): 0.9394803704507002, ('farfalla', 'rosa'): 0.6634009700030588, ('recinto', 'salto'): 0.6505464444799082, ('nichilismo', 'film'): 0.5835485078133711, ('asteroide', 'stella'): 0.8216879801335856, ('sommossa', 'disegno'): 0.44048376584606336, ('intimo', 'corpo'): 0.43128846183517205, ('Boeing', 'aereo'): 0.8985004700455775, ('cameo', 'interpretazione'): 0.619234539638481, ('semestre', 'quadrimestre'): 0, ('arancia', 'agrume'): 0.9789173082506498, ('ghiacciaio', 'riscaldamento globale'): 0.5118958330631778, ('galleria', 'percorso'): 0.7722676195145126}\n",
      "\n",
      "Pearson Correlation:  [[1.         0.57054785]\n",
      " [0.57054785 1.        ]]\n",
      "\n",
      "Spearman Correlation:  SpearmanrResult(correlation=0.6575257222585913, pvalue=2.130585658022415e-07)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "def main():\n",
    "    human_similarities_dictionary = get_human_similarities_dictionary()\n",
    "    \n",
    "    senses_dictionary = get_senses_dictionary(get_word_list(human_similarities_dictionary))\n",
    "    \n",
    "    NASARI_similarities_dictionary = get_NASARI_similarities_dictionary(human_similarities_dictionary, senses_dictionary)\n",
    "\n",
    "    human_similarities = []\n",
    "    NASARI_similarities = []\n",
    "    for word_pair in human_similarities_dictionary.keys():\n",
    "        if word_pair in NASARI_similarities_dictionary.keys():\n",
    "            human_similarities.append(float(human_similarities_dictionary[word_pair]))\n",
    "            NASARI_similarities.append(NASARI_similarities_dictionary[word_pair])\n",
    "    \n",
    "    print()\n",
    "    print(\"VALUTAZIONI DI SIMILARITA' UMANE: \")\n",
    "    print(human_similarities_dictionary)\n",
    "    print()\n",
    "    print(\"VALUTAZIONI DI SIMILARITA' DEL SISTEMA: \")\n",
    "    print(NASARI_similarities_dictionary)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print(\"Pearson Correlation: \",np.corrcoef(human_similarities, NASARI_similarities))\n",
    "    print()\n",
    "    print(\"Spearman Correlation: \",sp.stats.spearmanr(human_similarities, NASARI_similarities))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASSEGNAMENTI SYNSETS UMANI: \n",
      "{('recessione', 'PIL'): ('bn:00066516n', 'bn:00037570n'), ('Cesare', 'Giulio Cesare'): ('bn:00014550n', 'bn:00014550n'), ('paziente', 'sessione'): ('bn:00061017n', 'bn:00076588n'), ('comportamentismo', 'terapia'): ('bn:00009659n', 'bn:00076843n'), ('imperatore', 'costituzione'): ('bn:00014550n', 'bn:00059480n'), ('matematico', 'spettacolo'): ('bn:00053834n', 'bn:00067553n'), ('entropia', 'informazione'): ('bn:00031061n', 'bn:00046705n'), ('acqua di rose', 'olio di rosa'): ('bn:00068288n', 'bn:00007010n'), ('agrume', 'pompelmo'): ('bn:00019301n', 'bn:00019313n'), ('Regina Vittoria', 'Inghilterra'): ('bn:00065652n', 'bn:00013173n'), ('Giochi Olimpici', 'spirito'): ('bn:00058910n', 'bn:00040370n'), ('vescovo', 'musulmano'): ('bn:27267995n', 'bn:00055975n'), ('uomo', 'sospetto'): ('bn:00044576n', 'bn:00025884n'), ('meteorite', 'Terra'): ('bn:00054602n', 'bn:00029424n'), ('simbolo', 'segno'): ('bn:00075652n', 'bn:00075652n'), ('antropologia', 'New York'): ('bn:00004584n', 'bn:00041611n'), ('tramonto', 'tavolo'): ('bn:05692316n', 'bn:00075813n'), ('cittadina', 'città'): ('bn:00070724n', 'bn:00077773n'), ('giacca', 'acqua minerale'): ('bn:00047823n', 'bn:00055131n'), ('natura', 'flora'): ('bn:00057017n', 'bn:00035324n'), ('subroutine', 'compilatore'): ('bn:00036826n', 'bn:00021344n'), ('Hamadan', 'Roma'): ('bn:03266645n', 'bn:00015556n'), ('ombrello', 'stufa'): ('bn:00078920n', 'bn:00074479n'), ('onore', 'stima'): ('bn:00027103n', 'bn:00031973n'), ('insegna', 'dignità'): ('bn:00034960n', 'bn:00027103n'), ('schermo', 'monitor'): ('bn:00027675n', 'bn:00021486n'), ('joystick', 'radar'): ('bn:00022301n', 'bn:00054808n'), ('basmati', 'riso jasmine'): ('bn:00567353n', 'bn:02666084n'), ('medaglia', 'scarpe da ginnastica'): ('bn:23946490n', 'bn:00042319n'), ('legge', 'piscina'): ('bn:00048655n', 'bn:00056911n'), ('sorgente', 'scatola'): ('bn:00036077n', 'bn:00012524n'), ('teatro', 'batteria'): ('bn:00045002n', 'bn:00028891n'), ('flora', 'web browser'): ('bn:00035324n', 'bn:00013447n'), ('camicia', 'cardigan'): ('bn:00071142n', 'bn:00015958n'), ('poema', 'ritmo'): ('bn:15205441n', 'bn:00009396n'), ('profeta', 'prete'): ('bn:00064759n', 'bn:00024459n'), ('Oscar', 'stadio'): ('bn:00000571n', 'bn:00005532n'), ('backgammon', 'Go'): ('bn:00007779n', 'bn:00040833n'), ('farfalla', 'rosa'): ('bn:00014271n', 'bn:00068283n'), ('recinto', 'salto'): ('bn:00034048n', 'bn:00048558n'), ('nichilismo', 'film'): ('bn:00057710n', 'bn:00034471n'), ('asteroide', 'stella'): ('bn:00006608n', 'bn:00073964n'), ('sommossa', 'disegno'): ('bn:00047003n', 'bn:00028639n'), ('intimo', 'corpo'): ('bn:00079003n', 'bn:00011744n'), ('Boeing', 'aereo'): ('bn:01156257n', 'bn:00002275n'), ('cameo', 'interpretazione'): ('bn:02119437n', 'bn:00061560n'), ('semestre', 'quadrimestre'): ('bn:00000561n', 'bn:15658281n'), ('arancia', 'agrume'): ('bn:17389700n', 'bn:00019301n'), ('ghiacciaio', 'riscaldamento globale'): ('bn:00040579n', 'bn:00040681n'), ('galleria', 'percorso'): ('bn:00078606n', 'bn:00067975n')}\n",
      "\n",
      "'ASSEGNAMENTI SYNSETS DEL SISTEMA: \n",
      "{('recessione', 'PIL'): ('bn:00066516n', 'bn:00037570n'), ('Cesare', 'Giulio Cesare'): ('bn:00014550n', 'bn:00014550n'), ('paziente', 'sessione'): ('bn:00001742n', 'bn:03751534n'), ('comportamentismo', 'terapia'): ('bn:00009659n', 'bn:00076843n'), ('imperatore', 'costituzione'): ('bn:00014550n', 'bn:02436267n'), ('matematico', 'spettacolo'): ('bn:00053834n', 'bn:00305552n'), ('entropia', 'informazione'): ('bn:17267027n', 'bn:00046705n'), ('acqua di rose', 'olio di rosa'): ('bn:00068288n', 'bn:00007010n'), ('agrume', 'pompelmo'): ('bn:00019301n', 'bn:00041408n'), ('Regina Vittoria', 'Inghilterra'): ('bn:00065652n', 'bn:00030861n'), ('Giochi Olimpici', 'spirito'): ('bn:00058913n', 'bn:00044468n'), ('vescovo', 'musulmano'): ('bn:03012712n', 'bn:00047600n'), ('uomo', 'sospetto'): ('bn:00053097n', 'bn:00075447n'), ('meteorite', 'Terra'): ('bn:00054598n', 'bn:00029424n'), ('simbolo', 'segno'): ('bn:00075652n', 'bn:00075652n'), ('antropologia', 'New York'): ('bn:02529040n', 'bn:02530635n'), ('tramonto', 'tavolo'): ('bn:01888833n', 'bn:00075813n'), ('cittadina', 'città'): ('bn:00077773n', 'bn:00077773n'), ('giacca', 'acqua minerale'): ('bn:00041211n', 'bn:00055131n'), ('natura', 'flora'): ('bn:00081220n', 'bn:00012321n'), ('subroutine', 'compilatore'): ('bn:00036826n', 'bn:00021344n'), ('Hamadan', 'Roma'): ('bn:03266645n', 'bn:00660953n'), ('ombrello', 'stufa'): ('bn:00078920n', 'bn:00074479n'), ('onore', 'stima'): ('bn:00044654n', 'bn:00031654n'), ('insegna', 'dignità'): ('bn:00002823n', 'bn:00025772n'), ('schermo', 'monitor'): ('bn:00027675n', 'bn:00027675n'), ('joystick', 'radar'): ('bn:00022301n', 'bn:00054808n'), ('basmati', 'riso jasmine'): ('bn:00567353n', 'bn:02666084n'), ('medaglia', 'scarpe da ginnastica'): ('bn:00054078n', 'bn:00068586n'), ('legge', 'piscina'): ('bn:00064426n', 'bn:02332519n'), ('sorgente', 'scatola'): ('bn:00036077n', 'bn:00015103n'), ('teatro', 'batteria'): ('bn:00034270n', 'bn:00021287n'), ('flora', 'web browser'): ('bn:03260352n', 'bn:00013447n'), ('camicia', 'cardigan'): ('bn:00028687n', 'bn:00015958n'), ('poema', 'ritmo'): ('bn:00063193n', 'bn:00063201n'), ('profeta', 'prete'): ('bn:00064759n', 'bn:00057892n'), ('Oscar', 'stadio'): ('bn:00407538n', 'bn:00061898n'), ('backgammon', 'Go'): ('bn:00007779n', 'bn:00040833n'), ('farfalla', 'rosa'): ('bn:00012473n', 'bn:00062507n'), ('recinto', 'salto'): ('bn:00060140n', 'bn:00048558n'), ('nichilismo', 'film'): ('bn:00057710n', 'bn:00735555n'), ('asteroide', 'stella'): ('bn:00055203n', 'bn:00073965n'), ('sommossa', 'disegno'): ('bn:01480882n', 'bn:00028562n'), ('intimo', 'corpo'): ('bn:00021740n', 'bn:03119994n'), ('Boeing', 'aereo'): ('bn:01156257n', 'bn:00001697n'), ('cameo', 'interpretazione'): ('bn:03871797n', 'bn:00061560n'), ('semestre', 'quadrimestre'): None, ('arancia', 'agrume'): ('bn:00059249n', 'bn:00019301n'), ('ghiacciaio', 'riscaldamento globale'): ('bn:00040579n', 'bn:00040681n'), ('galleria', 'percorso'): ('bn:14530939n', 'bn:00061006n')}\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-728e68bd6425>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuratezza sulle coppie: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchecked\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mevaluated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-728e68bd6425>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0msynset_pair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_pair_synset_pair_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_pair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mhuman_synsets_pair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhuman_synsets_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_pair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0msynset_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mhuman_synsets_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mchecked\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msynset_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mhuman_synsets_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    human_similarities_dictionary = get_human_similarities_dictionary()\n",
    "    \n",
    "    senses_dictionary = get_senses_dictionary(get_word_list(human_similarities_dictionary))\n",
    "    \n",
    "    human_synsets_dictionary = get_human_synsets_dictionary()\n",
    "    \n",
    "    word_pair_synset_pair_dictionary = get_word_pair_synset_pair_dictionary(human_synsets_dictionary, senses_dictionary)\n",
    "    \n",
    "    print()\n",
    "    print(\"ASSEGNAMENTI SYNSETS UMANI: \")\n",
    "    print(human_synsets_dictionary)\n",
    "    print()\n",
    "    print(\"'ASSEGNAMENTI SYNSETS DEL SISTEMA: \")\n",
    "    print(word_pair_synset_pair_dictionary)\n",
    "    \n",
    "    print()\n",
    "    #calcolo accuratezza sui singoli elementi\n",
    "    checked = 0\n",
    "    for word_pair in human_synsets_dictionary.keys():\n",
    "        synset_pair = word_pair_synset_pair_dictionary[word_pair]\n",
    "        human_synsets_pair = human_synsets_dictionary[word_pair]\n",
    "        if synset_pair[0] == human_synsets_pair[0]:\n",
    "            checked += 1\n",
    "        if synset_pair[1] == human_synsets_pair[1]:\n",
    "            checked += 1\n",
    "    evaluated = len(human_synsets_dictionary.keys()) * 2\n",
    "    print(\"Accuratezza sui singoli elmenti: \", checked / evaluated)\n",
    "\n",
    "    #calcolo accuratezza sulle coppie\n",
    "    checked = 0\n",
    "    for word_pair in human_synsets_dictionary.keys():\n",
    "        synset_pair = word_pair_synset_pair_dictionary[word_pair]\n",
    "        human_synsets_pair = human_synsets_dictionary[word_pair]\n",
    "        if (synset_pair[0] == human_synsets_pair[0]) and (synset_pair[1] == human_synsets_pair[1]):\n",
    "            checked += 1\n",
    "    evaluated = len(human_synsets_dictionary.keys())\n",
    "    print(\"Accuratezza sulle coppie: \", checked / evaluated)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "687777cbfed9bcee7b08ad56f15c17d8908988aca6cd0ae5484f3a9e4851bb70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
