{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2d621f-5b87-49dd-b996-cce75f2c6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import utils \n",
    "import nltk\n",
    "import math\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09509e0-2614-4048-8b31-886bcfc046b0",
   "metadata": {},
   "source": [
    "FUNZIONI DI PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967261cf-febf-42e5-8b1d-b645fa4b4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rimuove le stowords da una lista di parole\n",
    "def remove_stopwords(words_list):\n",
    "    stopwords_list = get_stopwords()\n",
    "    return [value.lower() for value in words_list if value.lower() not in stopwords_list]\n",
    "\n",
    "#Rimuove la punteggiatura da una sentence\n",
    "#Restituisce la sentence senza punteggiature\n",
    "def remove_punctuation(sentence):\n",
    "    return re.sub(r'[^\\w\\s]','',sentence)\n",
    "   \n",
    "\n",
    "#Restituisce la l'insieme di stopwords dal file delle stopwords\n",
    "def get_stopwords():\n",
    "    stopwords = open(\"stop_words_FULL.txt\", \"r\")\n",
    "    stopwords_list = []\n",
    "    for word in stopwords:\n",
    "        stopwords_list.append(word.replace('\\n', ''))\n",
    "    stopwords.close()\n",
    "    return stopwords_list\n",
    "\n",
    "\n",
    "#Tokenizza la frase in input e ne affettua anche la lemmatizzazione della sue parole\n",
    "def tokenize(sentence):\n",
    "    words_list = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        if (tag[1][:2] == \"NN\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos = wn.NOUN))\n",
    "        elif (tag[1][:2] == \"VB\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.VERB))\n",
    "        elif (tag[1][:2] == \"RB\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.ADV))\n",
    "        elif (tag[1][:2] == \"JJ\"):\n",
    "             words_list.append(lmtzr.lemmatize(tag[0], pos = wn.ADJ))\n",
    "    return words_list\n",
    "\n",
    "#restituisce la bag of word per la frase o il paragrafo in oggetto\n",
    "#effettua il pre-processing, ovvero la rimozione delle stopwords, punteggiatura e lemmatizzazione(?)-> per ora no  \n",
    "def bag_of_words(sentence):\n",
    "    return set(remove_stopwords(tokenize(remove_punctuation(sentence))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63fabf3-55de-48c0-88ea-151e87c3f78a",
   "metadata": {},
   "source": [
    "FUNZIONI UTILI PER LA COSTRUZIONE DEI RIASSUNTO DEL TESTO DATO IN INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5de715f-b3e6-4220-b7d2-6774913e35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PARAGRAPH_LEN = 50\n",
    "\n",
    "#Le stigma words ci permettono di capire che NON stanno per essere dette cose importanti\n",
    "def get_stigma_words():\n",
    "    return ['no','not','i','you','she','he','we','they','it','me','him','her','us','them','mine','ours',\n",
    "            'hers','theirs','ourselves','myself','himself','who','whose','which','what','this','that',\n",
    "            'these','those','whom','whose']\n",
    "\n",
    "#Le bonus words ci permettono di capire che stanno per essere dette cose importanti\n",
    "def get_bonus_words():\n",
    "    return  ['better', 'worse', 'less', 'more', 'further', 'farther', 'best', 'worst', 'least', 'most',\n",
    "             'furthest', 'farthest', 'more', 'important','seen', 'all', 'fact', 'final', 'analysis',\n",
    "             'whole', 'brief', 'altogether', 'obviously','overall', 'ultimately', 'ordinarily',\n",
    "             'definitely','usually', 'emphasize', 'result','henceforth', 'additionally', 'main', \n",
    "             'aim','purpose', 'outline', 'investigation']\n",
    "\n",
    "\n",
    "def get_Nasari_vectors(query_string):\n",
    "    nasari_vectors = list()\n",
    "    file = open('utils/NASARI_vectors/dd-small-nasari-15.txt', 'r' , encoding=\"utf8\")\n",
    "    for line in file:\n",
    "        if query_string in line:\n",
    "            nasari_vectors.append(vector_format(line))\n",
    "    file.close()\n",
    "    return nasari_vectors\n",
    "                   \n",
    "#riceve in input una riga del file NASARI small e restituisce\n",
    "#un vettore NASARI formattato, per esempio, nel seguente modo:\n",
    "#[('million', '209.35'), ('number', '146.31'), ('mathematics', '61.3'), \n",
    "#('long scale', '53.31'), ('real number', '50.43'), ('numeral', '50.35'), \n",
    "#('short scale', '50.12'), ('digit', '42.17'), ('bally', '41.77'), ('millionaire', '41.31'), \n",
    "#('penguin', '41.11'), ('markov', '40.61'), ('complex number', '38.37'), ('infinity', '36.79')]\n",
    "def vector_format(nasari_line):\n",
    "    line_splitted = nasari_line.replace(\"\\n\", \"\").split(\";\")\n",
    "    word_score_list = []\n",
    "    for item in line_splitted[2:]:\n",
    "        if \"_\" in item:\n",
    "            word, score = item.split(\"_\")\n",
    "            word_score_list.append((word,score))\n",
    "            \n",
    "    return word_score_list\n",
    "\n",
    "#restituisce un dizionario, dove, ad ogni parola (chiave) è associata \n",
    "#una lista di vettori NASARI\n",
    "#MAPPING -APPROCCIO:\n",
    "#associare ad una word il set di vettori NASARI facendo matchare il wikititlepage del vettore\n",
    "#se la ricerca dei vettori avviene con la stringa del tipo ;Word; allora verrà\n",
    "#implementato l'approccio 1, restituendo le righe corrispondenti ai vettori\n",
    "#che contengono quella stringa\n",
    "def get_Nasari_vectors_for_bag_of_words(bag_of_words):\n",
    "    nasari_vectors_for_bag_of_words = dict()\n",
    "    for word in bag_of_words:\n",
    "        query_string = ';' + word.capitalize() + ';' #la ricerca avviene nel secondo approccio\n",
    "        nasari_vectors = get_Nasari_vectors(query_string)\n",
    "        if word not in nasari_vectors_for_bag_of_words.keys() and nasari_vectors:\n",
    "            nasari_vectors_for_bag_of_words[word] = nasari_vectors\n",
    "    return nasari_vectors_for_bag_of_words\n",
    "\n",
    "\"\"\"Approccio TITLE\"\"\"\n",
    "#Metodo utilizzato nell'approccio TITLE\n",
    "#il topic viene preso dal primo paragrafo del documento che in generale è il titolo\n",
    "def get_title_topic(document):\n",
    "    title = document[0]\n",
    "    return get_Nasari_vectors_for_bag_of_words(bag_of_words(title))\n",
    "\"\"\"Approccio TITLE\"\"\"\n",
    "\n",
    "\"\"\"Approccio CUE\"\"\"\n",
    "#Medoto utilizzato nell'approccio CUE\n",
    "#Restituisce il topic del paragrafo più importante del documento\n",
    "#il paragrafo più importante del documento è scelto in base alla prensenza di stigma word o bonus word\n",
    "#ad ogni paragrafo viene associato un punteggio che aumenta di 1 per ogni bonus word\n",
    "#e diminuisce di 1 per ogni stigma word al suo interno\n",
    "#viene stilato un ranking e come topic viene scelto il paragrafo con il punteggio più alto\n",
    "def get_topic(document):\n",
    "    paragraph_score = []\n",
    "    for paragraph in document:\n",
    "        paragraph_score.append((paragraph, get_CUE_score(paragraph)))\n",
    "    more_important_paragraph =  sorted(paragraph_score, key=lambda x: x[1], reverse = True)[0] #prendo il primo in classifica\n",
    "    print(\"MORE IMPORTANT PARAGRAPH: \\n\", more_important_paragraph)\n",
    "    print(bag_of_words(more_important_paragraph[0]))\n",
    "    return get_Nasari_vectors_for_bag_of_words(bag_of_words(more_important_paragraph[0]))\n",
    "\n",
    "#Restituisce uno score per il paragrafo in input\n",
    "#direttamente proporzionale alle bonus word e inversamente proporzionale alle stigma word\n",
    "#lo score è un numero intero positivo o negativo\n",
    "def get_CUE_score(paragraph):\n",
    "    word_list = tokenize(remove_punctuation(paragraph))\n",
    "    score = 0\n",
    "    for word in word_list:\n",
    "        if word in get_bonus_words(): score += 1\n",
    "        elif word in get_stigma_words(): score -= 1\n",
    "    return score\n",
    "\"\"\"Approccio CUE\"\"\"   \n",
    "      \n",
    "def get_context_paragraph(paragraph):\n",
    "    return get_Nasari_vectors_for_bag_of_words(bag_of_words(paragraph))\n",
    "\n",
    "\n",
    "#resistuisce il massimo weighted_overlap tra due concetti associati a due parole\n",
    "#i concetti sono liste di vettori, quindi massimizza il weighted_overlap tra due liste di\n",
    "#vettori NASARI\n",
    "def similarity(vector_list1, vector_list2):\n",
    "    max_overlap = 0\n",
    "    \n",
    "    for vector1 in vector_list1:\n",
    "        for vector2 in vector_list2:\n",
    "            overlap = math.sqrt(compute_weighted_overlap(vector1,vector2))\n",
    "            if overlap > max_overlap:\n",
    "                max_overlap = overlap\n",
    "    return max_overlap\n",
    "\n",
    "#calcola il weighted_overlap tra due vettori NASARI\n",
    "def compute_weighted_overlap(vector1,vector2):\n",
    "    overlap = 0\n",
    "    common_keys = get_common_keys(vector1, vector2)\n",
    "    \n",
    "    if len(common_keys) > 0:\n",
    "        numerator = 0\n",
    "        for q in common_keys:\n",
    "            numerator += (1 / (rank(q, vector1) + rank(q, vector2)))\n",
    "        \n",
    "        denominator = 0\n",
    "        for i in range(1, len(common_keys) + 1):\n",
    "            denominator += 1/ (2 * i)\n",
    "        \n",
    "        overlap = numerator / denominator\n",
    "        \n",
    "    return overlap\n",
    "            \n",
    "#restituisce le chiavi (dimensioni) comuni tra due vettori NASARI\n",
    "def get_common_keys(vector1, vector2):\n",
    "    common_keys = []\n",
    "    for word1,score1 in vector1:\n",
    "        for word2, score2 in vector2:\n",
    "            if word1 == word2:\n",
    "                common_keys.append(word1)\n",
    "    return common_keys\n",
    "\n",
    "#calcola il rango di una chiave (dimensione) all'interno del vettore NASARI in input\n",
    "def rank(key, vector):\n",
    "    for index,(word,value) in enumerate(vector):\n",
    "        if word == key: return index + 1\n",
    "            \n",
    "\n",
    "#Restituisce una lista di paragrafi del documento in input\n",
    "#il primo paragrafo rappresenta il titolo\n",
    "def parse_document(doc):\n",
    "    document = []\n",
    "    data = doc.read_text(encoding='utf-8')\n",
    "    lines = data.split('\\n')\n",
    "    \n",
    "    for index,line in enumerate(lines):\n",
    "        if line != \"\" and not \"#\" in line and (len(line) > MIN_PARAGRAPH_LEN or index == 3):\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            document.append(line)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f2b911-3ea0-4377-bc45-1ef0371c7a2b",
   "metadata": {},
   "source": [
    "FUNZIONI PER LA VALUTAZIONE DEI RISULTATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e65da8-2bee-4851-bac8-554a232a2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECISION e RECALL sui termini più importanti\n",
    "def BLUE_ROUGE_terms_evaluation(document,system_summary, reduction):\n",
    "     \n",
    "    gold_important_words = get_important_words(document, reduction)\n",
    "    system_words = get_words(system_summary)\n",
    "\n",
    "    print(\"Document's important words: \\n\", gold_important_words)\n",
    "    print(\"\\nSystem summary words: \\n\", system_words)\n",
    "    \n",
    "    precision = len(gold_important_words.intersection(system_words)) / len(system_words)\n",
    "    \n",
    "    recall = len(gold_important_words.intersection(system_words)) / len(gold_important_words)\n",
    "\n",
    "    return precision,recall\n",
    "    \n",
    "#restituisce il dizionario dei tf per ogni parola nel documento\n",
    "#ogni parola avrà tanti tf quanti sono i paragrafi del documento\n",
    "def get_tf_dictionary(document):\n",
    "    tf_dictionary = dict()\n",
    "    for paragraph in document[1:]:\n",
    "        bag_of_words_par = remove_stopwords(tokenize(remove_punctuation(paragraph)))\n",
    "        tf_par = Counter(bag_of_words_par)\n",
    "        for word in tf_par.keys():\n",
    "            if word not in tf_dictionary.keys(): tf_dictionary[word] = [tf_par[word] / len(bag_of_words_par)]\n",
    "            else: tf_dictionary[word].append(tf_par[word] / len(bag_of_words_par))\n",
    "    return tf_dictionary       \n",
    "            \n",
    "            \n",
    "def get_idf_dictionary(document,tf_dictionary):\n",
    "    idf_dictionary = dict()\n",
    "    n_paragraph = len(document[1:])\n",
    "    for word in tf_dictionary.keys():\n",
    "        n_paragraph_contains_word = 0\n",
    "        for paragraph in document[1:]:\n",
    "            if word in bag_of_words(paragraph):\n",
    "                n_paragraph_contains_word += 1\n",
    "        idf_dictionary[word] = math.log(n_paragraph / n_paragraph_contains_word)\n",
    "    return idf_dictionary\n",
    "\n",
    "\n",
    "def get_tf_idf_dictionary(tf_dictionary,idf_dictionary):\n",
    "    tf_idf_dictionary = dict()\n",
    "    for word in tf_dictionary.keys():\n",
    "        tfs_score = tf_dictionary[word] #tutti i term frequency associati alla word\n",
    "        idf_score = idf_dictionary[word] #idf associato alla word\n",
    "        tf_idf_dictionary[word] = mean([tf * idf_score for tf in tfs_score])\n",
    "    return tf_idf_dictionary\n",
    "\n",
    "#restituisce una lista di coppie (word, tf-idf) relative a document \n",
    "#ordinate secondo il valore di tf-idf        \n",
    "def get_important_words(document, reduction):\n",
    "    #word -> tf1,tf2,tf3,...\n",
    "    #ogni tf è relativo al termine per un paragrafo\n",
    "    #un termine avrà n tf per ogni paragrafo del documento\n",
    "    tf_dictionary = get_tf_dictionary(document)\n",
    "   \n",
    "    #word -> idf\n",
    "    #un termine avrà un solo idf\n",
    "    idf_dictionary = get_idf_dictionary(document, tf_dictionary)\n",
    "    \n",
    "    #un termine avrà n tf-idf. verrà preso il tf-idf medio\n",
    "    tf_idf_dictionary = get_tf_idf_dictionary(tf_dictionary, idf_dictionary)\n",
    "    \n",
    "    #calcoliamo il numero di termini da mantenere (saranno quelle più importanti)\n",
    "    #il numero di parole è dato da len(tf_idf_dictionary) * (100 - reduction)/100\n",
    "    percentage = (100 - reduction)/100\n",
    "    important_words_number = int(round(len(tf_idf_dictionary) * percentage))\n",
    "    \n",
    "    #vengono ordinati in modo decrescente gli score tf-idf\n",
    "    sorted_tf_idf = sorted(tf_idf_dictionary.items(), key=lambda x: x[1], reverse=True)[:important_words_number]\n",
    "    \n",
    "    #restituisco solo i termini (senza score)\n",
    "    important_words = set()\n",
    "    for item in sorted_tf_idf: important_words.add(item[0])\n",
    "    \n",
    "    return important_words\n",
    "\n",
    "#restituisce il bag of words di un documento\n",
    "def get_words(document):\n",
    "    bag_of_words_document = set()\n",
    "    for paragraph in document[1:]:\n",
    "        bag_of_words_par = (bag_of_words(paragraph))\n",
    "        bag_of_words_document = bag_of_words_document | bag_of_words_par\n",
    "    return bag_of_words_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f309a-c83c-4d85-a334-fc9412cc3dbd",
   "metadata": {},
   "source": [
    "FUNZIONE CHE EFFETTUA IL RIASSUNTO DI UN DOCUMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4860793b-b6dd-4bf9-ac4a-1a4f363c5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization(document, reduction, relevance_criteria):\n",
    "    \n",
    "    if relevance_criteria == 'title':\n",
    "        topic = get_title_topic(document)\n",
    "    elif relevance_criteria == 'cue':\n",
    "        topic = get_topic(document)\n",
    "    \n",
    "    print()\n",
    "    print(\"Topic of the file: \")\n",
    "    print(topic)\n",
    "    \n",
    "    paragraphs_overlap = []\n",
    "    for paragraph in document[1:]:\n",
    "        paragraph_context = get_context_paragraph(paragraph)\n",
    "        \n",
    "        average_topic_paragraph_overlap = 0 #overlap medio sul pragrafo corrente\n",
    "        match_count = 0 #conteggio totale degli overlap calcolati\n",
    "        for key1 in paragraph_context.keys():\n",
    "            for key2 in topic.keys():\n",
    "                #calcolo e sommo iterativamente la massimizzazione della similarità tra due concetti\n",
    "                #uno individuato dalla chiave nel contesto del paragrafo\n",
    "                #uno individuato dalla chiave nel topic\n",
    "                #ad ogni chiave corrisponde un concetto, individuato come una lista di vettori NASARI\n",
    "                average_topic_paragraph_overlap += similarity(paragraph_context[key1],\n",
    "                                                                               topic[key2])\n",
    "                match_count += 1\n",
    "        \n",
    "        #calcolo la media per il paragrafo corrente e aggiunto il paragrafo con il suo score\n",
    "        # in una lista di tuple (paragrafo,score)\n",
    "        if match_count != 0:\n",
    "            average_topic_paragraph_overlap = average_topic_paragraph_overlap / match_count\n",
    "            paragraphs_overlap.append((paragraph,average_topic_paragraph_overlap))\n",
    "    \n",
    "    #calcoliamo il numero di paragrafi da manterenere nel riassunto\n",
    "    number_of_paragraphs = len(paragraphs_overlap) - int(round((reduction / 100) * len(paragraphs_overlap), 0))\n",
    "    \n",
    "    #ordiniamo in modo descrescente la lista di tuple (paragrafo, score)\n",
    "    paragraphs_overlap = sorted(paragraphs_overlap, key=lambda x: x[1], reverse = True)[:number_of_paragraphs]\n",
    "                    \n",
    "    #ordiniamo i paragrafi nella lista list_of_paragraphs tenendo conto dell'ordine in cui i paragrafi\n",
    "    #compaiono nel documento originale\n",
    "    summary = []\n",
    "    summary.append(document[0]) #aggiungiamo il titolo come primo paragrafo del riassunto\n",
    "    list_of_paragraphs = [paragraph[0] for paragraph in paragraphs_overlap]\n",
    "    for paragraph in document[1:]: \n",
    "        if paragraph in list_of_paragraphs: \n",
    "            summary.append(paragraph)\n",
    "            \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0ed4e5-b19b-42fe-879c-64746036c945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name :  Andy-Warhol.txt\n",
      "file name :  Ebola-virus-disease.txt\n",
      "file name :  Life-indoors.txt\n",
      "file name :  Napoleon-wiki.txt\n",
      "file name :  Trump-wall.txt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserire il nome del file da riassumere (compreso di .txt):\n",
      " Napoleon-wiki.txt\n",
      "Inserire la percentuale di riduzione (10,20,30):\n",
      " 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MORE IMPORTANT PARAGRAPH: \n",
      " ('He won most of these wars and the vast majority of his battles, building a large empire that ruled over much of continental Europe before its final collapse in 1815. He is considered one of the greatest commanders in history, and his wars and campaigns are studied at military schools worldwide. ', 2)\n",
      "{'collapse', 'great', 'campaign', 'battle', 'build', 'school', 'empire', 'final', 'commander', 'continental', 'vast', 'consider', 'war', 'large', 'rule', 'study', 'win', 'worldwide', 'majority', 'history', 'military', 'europe'}\n",
      "\n",
      "Topic of the file: \n",
      "{'school': [[('school', '1270.3'), ('student', '524.74'), ('education', '227.91'), ('private school', '144.22'), ('gymnasium', '136.4'), ('secondary school', '116.67'), ('grade', '104.8'), ('middle school', '102.7'), ('year', '91.08'), ('sunday school', '82.98'), ('lyceum', '82.46'), ('pupil', '81.26'), ('cram', '79.17'), ('lycée', '71.46')]], 'empire': [[('empire', '1899.57'), ('bc', '366.65'), ('emperor', '345.02'), ('century', '323.85'), ('kingdom', '309.35'), ('imperial', '225.55'), ('roman', '201.66'), ('ottoman', '198.41'), ('rule', '179.05'), ('dynasty', '175.65'), ('cyrus', '168.56'), ('period', '133.23'), ('roman empire', '128.99'), ('territory', '124.87')]], 'commander': [[('rank', '1438.45'), ('commander', '878.49'), ('officer', '402.27'), ('captain', '284.27'), ('insignia', '272.71'), ('command', '246.3'), ('navy', '241.82'), ('coontz', '216.36'), ('epaulette', '197.5'), ('lieutenant', '196.39'), ('army', '180.58'), ('police', '153.83'), ('superintendent', '147.64'), ('senior', '124.3')]], 'majority': [[('vote', '1519.99'), ('majority', '618.61'), ('voter', '571.17'), ('referendum', '530.6'), ('candidate', '481.29'), ('election', '460.29'), ('amendment', '453.47'), ('voting', '423.69'), ('constitution', '378.49'), ('senate', '281.42'), ('ballot', '265.3'), ('quorum', '239.15'), ('minority', '202.1'), ('garrard', '173.99')]], 'history': [[('history', '1837.97'), ('historian', '794.07'), ('historical', '443.71'), ('historiography', '314.08'), ('study', '187.96'), ('social', '131.18'), ('past', '99.89'), ('humanity', '93.98'), ('scholar', '66.84'), ('modern', '66.03'), ('discipline', '60.6'), ('narrative', '58.68'), ('journal', '52.05'), ('american', '48.98')]]}\n",
      "_______________________________________________________________\n",
      "\n",
      "RIASSUNTO:\n",
      "\n",
      "Napoleone Bonaparte.\n",
      "\n",
      "He was Emperor of the French as Napoleon I from 1804 until 1814 and again briefly in 1815 during the Hundred Days. Napoleon dominated European and global affairs for more than a decade while leading France against a series of coalitions in the Napoleonic Wars. \n",
      "\n",
      "He won most of these wars and the vast majority of his battles, building a large empire that ruled over much of continental Europe before its final collapse in 1815. He is considered one of the greatest commanders in history, and his wars and campaigns are studied at military schools worldwide. \n",
      "\n",
      "Napoleon's political and cultural legacy has endured as one of the most celebrated and controversial leaders in human history.\n",
      "\n",
      "He was born in Corsica to a relatively modest Italian family from minor nobility. He was serving as an artillery officer in the French army when the French Revolution erupted in 1789. He rapidly rose through the ranks of the military, seizing the new opportunities presented by the Revolution and becoming a general at age 24. \n",
      "\n",
      "The French Directory eventually gave him command of the Army of Italy after he suppressed the 13 Vendémiaire revolt against the government from royalist insurgents. \n",
      "\n",
      "At age 26, he began his first military campaign against the Austrians and the Italian monarchs aligned with the Habsburgs—winning virtually every battle, conquering the Italian Peninsula in a year while establishing \"sister republics\" with local support, and becoming a war hero in France. \n",
      "\n",
      "In 1798, he led a military expedition to Egypt that served as a springboard to political power. He orchestrated a coup in November 1799 and became First Consul of the Republic. After the Peace of Amiens in 1802, Napoleon turned his attention to France's colonies. He sold the Louisiana Territory to the United States, and he attempted to restore slavery to the French Caribbean colonies. However, while he was successful in restoring slavery in the eastern Caribbean, Napoleon failed in his attempts to subdue Saint-Domingue, and the colony that France once proudly boasted of as the \"Pearl of the Antilles\" became independent as Haiti in 1804. Napoleon's ambition and public approval inspired him to go further, and he became the first Emperor of the French in 1804. \n",
      "\n",
      "Intractable differences with the British meant that the French were facing a Third Coalition by 1805. Napoleon shattered this coalition with decisive victories in the Ulm Campaign and a historic triumph over the Russian Empire and Austrian Empire at the Battle of Austerlitz which led to the dissolution of the Holy Roman Empire. \n",
      "\n",
      "In 1806, the Fourth Coalition took up arms against him because Prussia became worried about growing French influence on the continent. Napoleon quickly defeated Prussia at the battles of Jena and Auerstedt, then marched his Grande Armée deep into Eastern Europe and annihilated the Russians in June 1807 at the Battle of Friedland. France then forced the defeated nations of the Fourth Coalition to sign the Treaties of Tilsit in July 1807, bringing an uneasy peace to the continent. Tilsit signified the high-water mark of the French Empire. \n",
      "\n",
      "In 1809, the Austrians and the British challenged the French again during the War of the Fifth Coalition, but Napoleon solidified his grip over Europe after triumphing at the Battle of Wagram in July.\n",
      "\n",
      "The French launched a major invasion of Russia in the summer of 1812. The campaign destroyed Russian cities, but did not yield the decisive victory Napoleon wanted. It resulted in the collapse of the Grande Armée and inspired a renewed push against Napoleon by his enemies. In 1813, Prussia and Austria joined Russian forces in the War of the Sixth Coalition against France. A lengthy military campaign culminated in a large Allied army defeating Napoleon at the Battle of Leipzig in October 1813, but his tactical victory at the minor Battle of Hanau allowed retreat onto French soil. \n",
      "\n",
      "The Allies then invaded France and captured Paris in the spring of 1814, forcing Napoleon to abdicate in April. He was exiled to the island of Elba off the coast of Tuscany, and the Bourbon dynasty was restored to power. Napoleon escaped from Elba in February 1815 and took control of France once again. The Allies responded by forming a Seventh Coalition which defeated him at the Battle of Waterloo in June. The British exiled him to the remote island of Saint Helena in the South Atlantic, where he died six years later at the age of 51.\n",
      "\n",
      "Napoleon's influence on the modern world brought liberal reforms to the numerous territories that he conquered and controlled, such as the Low Countries, Switzerland, and large parts of modern Italy and Germany. He implemented fundamental liberal policies in France and throughout Western Europe. His Napoleonic Code has influenced the legal systems of more than 70 nations around the world. \n",
      "\n",
      "British historian Andrew Roberts states: \"The ideas that underpin our modern world—meritocracy, equality before the law, property rights, religious toleration, modern secular education, sound finances, and so on—were championed, consolidated, codified and geographically extended by Napoleon. To them he added a rational and efficient local administration, an end to rural banditry, the encouragement of science and the arts, the abolition of feudalism and the greatest codification of laws since the fall of the Roman Empire\".\n",
      "\n",
      "_______________________________________________________________\n",
      "_______________________________________________________________\n",
      "Document's important words: \n",
      " {'eventually', 'idea', 'controversial', 'choke', 'decade', 'austrians', 'difference', 'deep', 'efficient', 'art', 'abdicate', 'nation', 'extend', 'recur', 'remote', 'historian', 'dynasty', 'establish', 'finance', 'south', 'suppress', 'intractable', 'directory', 'saint', 'policy', 'solidify', 'legal', 'attempt', 'local', 'mark', 'science', 'modern', 'declare', 'education', 'law', 'escape', 'code', 'low', 'worried', 'monarch', 'routinely', 'champion', 'abolition', 'support', 'serve', 'equality', 'rank', 'seventh', 'legacy', 'revolution', 'habsburgswinning', 'royalist', 'july', 'sound', 'meant', 'invade', 'brother', 'napoleons', 'revolt', 'collapse', 'island', 'guerrilla', 'atlantic', 'great', 'officer', 'spring', 'jena', 'onwere', 'form', 'tilsit', 'caribbean', 'shatter', 'influence', 'conquer', 'administration', 'year', 'austerlitz', 'andrew', 'empire', 'wars', 'continental', 'vast', 'helena', 'secular', 'large', 'add', 'series', 'treaties', 'march', 'fourth', 'roman', 'encouragement', 'launch', 'exile', 'economic', 'nobility', 'geographically', 'banditry', 'opportunity', 'ulm', 'holy', 'italy', 'rural', 'bring', 'control', 'majority', 'army', 'history', 'align', 'entice', 'reform', 'implement', 'conflict', 'colony', 'codified', 'peninsula', 'europe', 'vendémiaire', 'dominate', 'endure', 'austrian', 'auerstedt', 'russians', 'family', 'rapidly', 'mainland', 'general', 'uneasy', 'build', 'victory', 'invasion', 'consolidated', 'peninsular', 'revolutionary', 'extensive', 'prominence', 'property', 'rational', 'codification', 'restore', 'napoleone', 'school', 'spain', 'final', 'italian', 'commander', 'major', 'consider', 'seize', 'capture', 'sister', 'coast', 'political', 'continent', 'april', 'religious', 'rise', 'slavery', 'numerous', 'study', 'spanish', 'liberal', 'prussia', 'hop', 'celebrated', 'client', 'napoleonic', 'respond', 'successful', 'paris', 'underpin', 'human', 'government', 'win', 'germany', 'portuguese', 'lead', 'wagram', 'iberian', 'bourbon', 'age', 'system', 'diplomatic', 'die', 'defeated', 'days', 'bear', 'signify', 'decisive', 'challenge', 'russia', 'feudalism', 'artillery', 'third', 'destroy', 'february', 'feature', 'emperor', 'minor', 'warfare', 'trade', 'worldmeritocracy', 'annihilate', 'summer', 'territory', 'waterloo', 'occupy', 'arm', 'violate', 'triumph', 'global', 'european', 'erupt', 'insurgent', 'fundamental', 'dissolution', 'statesman', 'friedland', 'allies', 'face', 'buonaparte', 'switzerland', 'republic', 'rule', 'russian', 'historic', 'grow', 'roberts', 'king', 'elba', 'sign', 'tuscany', 'consequence', 'command', 'cultural', 'affair', 'hero', 'toleration', 'fall', 'worldwide', 'grip', 'joseph', 'unwilling', 'virtually', 'corsica', 'bonaparte', 'countries', 'reduced', 'highwater', 'leader', 'western', 'modest'}\n",
      "\n",
      "System summary words: \n",
      " {'eventually', 'idea', 'campaign', 'controversial', 'battle', 'decade', 'austrians', 'difference', 'deep', 'efficient', 'abdicate', 'nation', 'art', 'extend', 'remote', 'historian', 'dynasty', 'frances', 'establish', 'south', 'finance', 'renew', 'suppress', 'intractable', 'directory', 'saint', 'policy', 'solidify', 'legal', 'attempt', 'local', 'mark', 'science', 'leipzig', 'modern', 'june', 'escape', 'education', 'law', 'code', 'low', 'worried', 'monarch', 'champion', 'abolition', 'support', 'serve', 'equality', 'rank', 'seventh', 'legacy', 'revolution', 'habsburgswinning', 'force', 'austria', 'royalist', 'july', 'sound', 'meant', 'invade', 'napoleons', 'revolt', 'collapse', 'island', 'atlantic', 'great', 'sell', 'officer', 'spring', 'peace', 'jena', 'onwere', 'sixth', 'tilsit', 'form', 'caribbean', 'conquer', 'year', 'shatter', 'influence', 'culminate', 'administration', 'saintdomingue', 'austerlitz', 'city', 'october', 'coup', 'andrew', 'empire', 'wars', 'continental', 'vast', 'subdue', 'ambition', 'helena', 'secular', 'large', 'add', 'series', 'treaties', 'grande', 'fourth', 'roman', 'encouragement', 'public', 'launch', 'exile', 'nobility', 'geographically', 'independent', 'opportunity', 'orchestrate', 'banditry', 'egypt', 'ulm', 'holy', 'italy', 'rural', 'bring', 'tactical', 'majority', 'control', 'army', 'history', 'align', 'hanau', 'reform', 'push', 'implement', 'attention', 'colony', 'inspire', 'codified', 'peninsula', 'europe', 'vendémiaire', 'endure', 'austrian', 'dominate', 'amiens', 'coalition', 'auerstedt', 'russians', 'family', 'french', 'rapidly', 'eastern', 'general', 'victory', 'build', 'uneasy', 'invasion', 'consolidated', 'allied', 'rational', 'western', 'property', 'restore', 'codification', 'school', 'final', 'commander', 'italian', 'major', 'consider', 'seize', 'war', 'sister', 'capture', 'british', 'coast', 'political', 'continent', 'april', 'religious', 'rise', 'slavery', 'springboard', 'numerous', 'study', 'proudly', 'prussia', 'yield', 'liberal', 'celebrated', 'napoleonic', 'respond', 'successful', 'pearl', 'paris', 'underpin', 'human', 'win', 'government', 'germany', 'louisiana', 'lead', 'enemy', 'wagram', 'die', 'bourbon', 'age', 'system', 'haiti', 'military', 'fail', 'antilles', 'days', 'defeated', 'bear', 'consul', 'decisive', 'signify', 'challenge', 'russia', 'feudalism', 'artillery', 'third', 'destroy', 'february', 'emperor', 'minor', 'worldmeritocracy', 'annihilate', 'soil', 'summer', 'territory', 'waterloo', 'allow', 'arm', 'turn', 'european', 'power', 'global', 'approval', 'erupt', 'insurgent', 'expedition', 'triumph', 'dissolution', 'fundamental', 'lengthy', 'result', 'friedland', 'allies', 'face', 'france', 'republic', 'switzerland', 'rule', 'russian', 'defeat', 'historic', 'grow', 'roberts', 'elba', 'sign', 'tuscany', 'affair', 'cultural', 'command', 'hero', 'toleration', 'join', 'fall', 'worldwide', 'grip', 'retreat', 'napoleon', 'virtually', 'corsica', 'boast', 'united', 'november', 'armée', 'countries', 'highwater', 'leader', 'march', 'modest'}\n",
      "_______________________________________________________________\n",
      "Precision sui termini significativi:  0.775\n",
      "Recall sui termini significativi:  0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #l'utente può riassumere un insieme di file\n",
    "    #prendiamo la lista di file con estensione .txt nella cartella docs\n",
    "    files = Path('utils/docs/').glob('*.txt')\n",
    "    for file in files:\n",
    "        print(\"file name : \",file.name)\n",
    "    files.close()\n",
    "    \n",
    "    #l'utente inserisce il nome del file che vuole riassumere\n",
    "    file_name = input(\"Inserire il nome del file da riassumere (compreso di .txt):\\n\")\n",
    "    \n",
    "    #l'utente inserisce la percentuale di riduzione del riassunto\n",
    "    reduction = int(input(\"Inserire la percentuale di riduzione (10,20,30):\\n\"))\n",
    "    \n",
    "    #-------FASE DI SUMMARIZATION--------#\n",
    "    files = Path('utils/docs/').glob('*.txt')\n",
    "    document = None\n",
    "    for file in files:\n",
    "        if file.name == file_name:\n",
    "            document = file\n",
    "            summary = summarization(parse_document(file), reduction, relevance_criteria='cue')\n",
    "            print(\"_______________________________________________________________\")\n",
    "            print(\"\\nRIASSUNTO:\\n\")\n",
    "            for par in summary:\n",
    "                print(par)\n",
    "                print()\n",
    "            print(\"_______________________________________________________________\")\n",
    "    files.close()\n",
    "    \n",
    "    #-------VALUTAZIONE SUI TERMINI------#\n",
    "    print(\"_______________________________________________________________\")\n",
    "    precision,recall = BLUE_ROUGE_terms_evaluation(parse_document(document),summary, reduction)\n",
    "    \n",
    "    print(\"_______________________________________________________________\")\n",
    "    #BLUE evaluation\n",
    "    print(\"Precision sui termini significativi: \",precision)\n",
    "    \n",
    "    #ROUGE evaluation\n",
    "    print(\"Recall sui termini significativi: \",recall)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
